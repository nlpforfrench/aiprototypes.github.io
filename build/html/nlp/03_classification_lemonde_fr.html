<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Transformers in NLP with PyTorch, TensorFlow and Hugging Face" href="../transformers/index.html" /><link rel="prev" title="Classification de prénoms en genre (masculin/féminin) 🇫🇷" href="02_classification_prenoms_fr.html" />

    <meta name="generator" content="sphinx-6.1.3, furo 2021.02.28.beta28"/>
        <title>Text Classification: du TF-IDF aux word embeddings en passant par features expertes 🇫🇷 - </title>
      <link rel="stylesheet" href="../static/styles/furo.css?digest=be5985a4059b5c2cd56ed0804790452beca62674">
    <link rel="stylesheet" href="../static/pygments.css">
    <link media="(prefers-color-scheme: dark)" rel="stylesheet" href="../static/pygments_dark.css">
    


<style>
  :root {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media (prefers-color-scheme: dark) {
    :root {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
  }

  /* For allowing end-user-specific overrides */
  .override-light {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  .override-dark {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
  }
</style><link rel="stylesheet" type="text/css" href="../static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../static/styles/furo.css" />
    <link rel="stylesheet" type="text/css" href="../static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../static/custom.css" />
    <link rel="stylesheet" href="../static/styles/furo-extensions.css?digest=d391b54134226e4196576da3bdb6dddb7e05ba2b"></head>
  <body dir="">
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke-width="1.5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z"/>
      <line x1="4" y1="6" x2="20" y2="6" />
      <line x1="10" y1="12" x2="20" y2="12" />
      <line x1="6" y1="18" x2="20" y2="18" />
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand"></div></a>
    </div>
    <div class="header-right">
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text"></span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html">
  <input class="sidebar-search" placeholder=Search name="q">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">NLP and Machine Learning-related</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label for="toctree-checkbox-1"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_compara_anno_fr.html">Comparer Spacy, StanfordNLP et TreeTagger sur un corpus oral et un corpus de presse 🇫🇷</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_classification_prenoms_fr.html">Classification de prénoms en genre (masculin/féminin) 🇫🇷</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Text Classification: du TF-IDF aux word embeddings en passant par features expertes 🇫🇷</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../transformers/index.html">Transformers in NLP with PyTorch, TensorFlow and Hugging Face</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label for="toctree-checkbox-2"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../transformers/01_theorie_en.html">10 questions on Bert 🇬🇧</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transformers/01_theorie_fr.html">10 questions sur Bert 🇫🇷</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transformers/02_firstBert_fr.html">Classification de commentaires avec Camembert sans prise de tête : les fondamentaux 🇫🇷</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../better_programmer/index.html">Better Programmer</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label for="toctree-checkbox-3"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/01_python_fr.html">Mieux programmer en Python 🇫🇷</a></li>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/02_git3_en.html">A serious guide to git 🇬🇧</a></li>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/03_jupyter_remote_pycharm.html">Connect to remote jupyter notebook in Pycharm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/04_oop_web_scraping_en.html">Understand objected-oriented programming (OOP) by building a minimal Web Scraping framework 🇬🇧</a></li>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/05_oop_web_scraping_cooper_en.html">Be a responsible programmer when doing Object-Oriented Programming 🇬🇧</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../algo/index.html">Algorithms and data structures by examples in Python</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label for="toctree-checkbox-4"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../algo/01_intro_en.html">Algorithm or many ways of solving a problem 🇬🇧</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/01_intro_fr.html">Algorithme ou plusieurs façons de résoudre un problème 🇫🇷</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/02_ds_en.html">Data structures or many ways of organizing your stuff 🇬🇧</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/099algo_map.html">Roadmap and cheatsheet of algorithms and data structures</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../web/index.html">Web Related</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label for="toctree-checkbox-5"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../web/01_lemonde_en.html">Complete tutorial on scraping French news from Le Monde 🇬🇧</a></li>
<li class="toctree-l2"><a class="reference internal" href="../web/01_lemonde_fr.html">Scraper « le monde » et construire ton propre corpus 🇫🇷</a></li>
<li class="toctree-l2"><a class="reference internal" href="../web/02_forum_en.html">On your way to scraping French forums 🇬🇧</a></li>
<li class="toctree-l2"><a class="reference internal" href="../web/03_django_en.html">Deploying Django app on Ubuntu at digitalocean + SSL certificate 🇬🇧</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../linguistique_informatique/index.html">Computational Linguistics in R</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label for="toctree-checkbox-6"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../linguistique_informatique/01_zipf_fr.html">La loi de Zipf illustrée avec gutenbergr en R 🇫🇷</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linguistique_informatique/02_mca_ergatif_fr.html">Analyse des Correspondances Multiples : le cas de l’ergatif en warlipiri 🇫🇷</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linguistique_informatique/03_pca_inclusion_fr.html">Analyse en composantes principales (PCA) : prépositions d’inclusion en français 🇫🇷</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../high_performance_python/index.html">High performance computing</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label for="toctree-checkbox-7"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../high_performance_python/01_parallel_primer_en.html">Parallelization in Python: a beginner’s guide (1, using map)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../codebase/index.html">My Codebase</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label for="toctree-checkbox-8"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../codebase/01_bash.html">My codebase for bash/shell script (macOS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../codebase/02_tmux.html">Tumux-related code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../codebase/03_python.html">My python codebase (including packages/libraries)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../codebase/05_pytorch.html">Pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../codebase/06_pandas.html">Pandas codebase</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../math/index.html">Mathematics in Machine Learning and NLP</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label for="toctree-checkbox-9"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../math/01_math_fr.html">Machine Learning : algorithmes et mathématiques 🇫🇷</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/01_math_fr.html">Machine Learning : algorithmes et mathématiques 🇫🇷</a></li>
</ul>
</li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <main class="main">
    <div class="content">
      <article role="main">
        <label class="toc-overlay-icon toc-content-icon" for="__toc">
          <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
        </label>
        <section id="text-classification-du-tf-idf-aux-word-embeddings-en-passant-par-features-expertes">
<h1>Text Classification: du TF-IDF aux word embeddings en passant par features expertes 🇫🇷<a class="headerlink" href="#text-classification-du-tf-idf-aux-word-embeddings-en-passant-par-features-expertes" title="Permalink to this heading">¶</a></h1>
<p><a class="reference external" href="https://scholar.google.fr/citations?user=vKAMMpwAAAAJ&amp;hl=en">Xiaoou WANG</a>, <a class="reference external" href="https://www.linkedin.com/in/xingyu-liu-aba896a1/">Xingyu LIU</a></p>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">¶</a></h2>
<p>La classification de textes est une tâche courante en traitement automatique des langues (TAL). Dans ce tutoriel nous allons explorer diverses features (TF-IDF, plongement lexical, features linguistiques) alimentant à leur tour des modèles variés dont entre autres la régression logistique, classification naïve bayésienne et perceptron multicouche.</p>
<p>Le but de ce tutoriel est de construire un classifieur qui permet de catégoriser correctement des textes en 3 classes : société, économie et politique.</p>
<div class="admonition-teaser admonition">
<p class="admonition-title">Teaser</p>
<p>Exclusivités :D</p>
</div>
<ol class="simple">
<li><p>Le corpus a été construit grâce au site des archives de « le monde ». Regardez <span class="xref myst">ici</span> pour un tutoriel rapide.</p></li>
<li><p>Une mise en parallèle a été soigneusement construite pour montrer l’efficacité des vecteurs lexicaux entraînés sur un corpus spécifique qui atteint la même performance d’un modèle à partir du corpus frWac de 1.6 milliards de mots  (Fauconnier, 2015).</p></li>
<li><p>Le package Lime (Ribeiro et al., 2016) a été utilisé pour comprendre et par la suite améliorer les features.</p></li>
<li><p>Quelques features linguistiques dites expertes ont été construites pour améliorer la performance de classification suite à une sélection manuelle s’appuyant sur la régression logistique.</p></li>
<li><p>Ce tutoriel est un issu d’un travail d’équipe, nous avons veillé au bon déroulement et à la bonne répartition des tâches en mettant en place toute une panoplie d’outils en logistique comme <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">méthode</span> <span class="pre">agile</span></code>, <a class="reference external" href="https://github.com/xiaoouwang/tuto_classification">Github</a>, <code class="docutils literal notranslate"><span class="pre">Omniplan</span></code> (outil de gestion de projet) et un document <a class="reference external" href="https://docs.google.com/document/d/11vaB74HV0GxerkVm9Pv_mgnhXN27QVegFYPdPA34t5g/edit?usp=sharing">Google Docs</a> auquel vous pouvez vous référer pour revoir comment ce tutoriel d’équipe a été réalisé pendant plus d’un mois.</p></li>
</ol>
<p>La répartition des tâches est illustrée succinctement par la Figure 1 :</p>
<p><img alt="" src="../_images/ac2e3489.png"/></p>
<p>Figure 1 : Répartition des tâches pendant l’écriture de ce tutoriel</p>
</section>
<section id="structure-du-tutoriel">
<h2>Structure du tutoriel<a class="headerlink" href="#structure-du-tutoriel" title="Permalink to this heading">¶</a></h2>
<ol class="simple">
<li><p>Nous présentons le prétraitement de notre corpus.</p></li>
<li><p>Ensuite nous utilisons TF-IDF comme feature et un classifieur bayésien pour établir une baseline. Le package <code class="docutils literal notranslate"><span class="pre">Lime</span></code> est utilisé pour comprendre le fonctionnement du classifieur qui a ensuite permis une légère amélioration de performance.</p></li>
<li><p>La baseline établie, divers modèles vectoriels sont entraînés sur des corpus de différentes tailles en utilisant différents paramètres. Cela nous a permis d’étudier les effets des paramètres et de la taille du corpus d’entraînement.</p></li>
<li><p>Enfin pour davantage augmenter la précision de classification nous introduisons quelques features linguistiques expertes, ces dernières étant soumises à un test basé sur la régression logistique pour que les features les plus pertinentes puissent être mises en avant.</p></li>
</ol>
</section>
<section id="pretraitement-du-corpus">
<h2>Prétraitement du corpus<a class="headerlink" href="#pretraitement-du-corpus" title="Permalink to this heading">¶</a></h2>
<p>Nous avons scrapé 9000 articles par thème. Les thèmes principaux sont : société, sport, économie, culture et politique. Nous avons ensuite sélectionné aléatoirement 1000 articles pour la tâche de classification.</p>
<p>La tokenisation a été effectuée avec le package Stanza (Qi et al., 2020). Ce tokeniseur a notamment l’avantage de regrouper par défaut des mots séparés par tiret du type « gratte-ciel », alors que dans Spacy un tel comportement nécessite une configuration ad hoc engendrant d’autres problèmes.</p>
<p>Nous avons aussi essayé de regrouper les entités nommées dans un seul token car cela permet de garder des informations sémantiques intactes. Dans Spacy il est facile d’y procéder ainsi mais dans Stanza il n’existe pas de fonction pré-définie. Nous avons donc soumis un <a class="reference external" href="https://github.com/stanfordnlp/stanza/issues/583">issue</a> sur Github et proposé notre propre solution sur le même lien au cas où cela pourrait servir la communauté.</p>
<p>Ensuite nous avons lemmatisé les tokens et enlevé les mots vides et ponctuation. Pour la liste des mots vides nous avons combiné les ensembles proposés par <code class="docutils literal notranslate"><span class="pre">NLTK</span></code> et <code class="docutils literal notranslate"><span class="pre">Spacy</span></code>. Notons que cette étape, en enlevant les tokens peu pertinents à chaque document, constitue en essence une tentative de réduction de dimensionnalité.</p>
<p>Enfin nous avons mis tous les tokens en minuscules. L’ensemble des opérations est illustré par la Figure 2 :</p>
<p><img alt="" src="../_images/768a8e62.png"/></p>
<p>Figure 2 : Prétraitement en amont des articles en vue de la classification</p>
<p>Notons que nous avons aussi préparé une version enrichie du corpus en xml pour calculer des features expertes. Il y a en tout 6 colonnes signifiant id, token, lemme, partie du discours, tête et relation de dépendance. Par contraintes d’espace nous ne détaillons pas la procédure de préparation. Chaque article est enchâssé dans le tag <code class="docutils literal notranslate"><span class="pre">&lt;art&gt;</span></code> avec label comme attribut et classe comme valeur. Ensuite chaque phrase est contenue dans un tag <code class="docutils literal notranslate"><span class="pre">&lt;s&gt;</span></code>. La Figure 3 montre la structure du fichier xml :</p>
<p><img alt="" src="../_images/c6849494.png"/></p>
<p>Figure 3 : Structure du corpus enrichi en xml</p>
</section>
<section id="classification-de-textes">
<h2>Classification de textes<a class="headerlink" href="#classification-de-textes" title="Permalink to this heading">¶</a></h2>
<section id="etablissement-dune-baseline">
<h3>Établissement d’une baseline<a class="headerlink" href="#etablissement-dune-baseline" title="Permalink to this heading">¶</a></h3>
<p>Vu que notre classifieur recourra principalement au plongement lexical, il nous a paru utile d’établir une baseline en utilisant un vecteur TF-IDF.</p>
<p>Un document peut être représenté de diverses façons selon le traitement des mots contenus dans le document. Le modèle le plus simple est le sac de mots qui compte l’occurrence de chaque token afin de générer une matrice documents-termes (MDT). Ce modèle est quelque peu simpliste car l’occurrence des tokens augmente en fonction de la longueur du document. Pour remédier à ce défaut la MDT peut être modifiée pour représenter non plus la fréquence absolue mais la fréquence relative des tokens. Cependant il subsiste toujours le problème des mots vides car ces derniers sont quasiment toujours les plus fréquents (cf. la loi de Zipf à ce propos).</p>
<p>Pour faire face à ce problème une autre mesure est proposée : celle de TF-IDF, la formule de cette mesure est la suivante :</p>
<figure class="align-center" id="id1">
<img alt="../_images/a322e8b3.png" src="../_images/a322e8b3.png"/>
<figcaption>
<p><span class="caption-text">Figure 4 : Formule de TF-IDF</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>L’efficacité de cette mesure est basée sur l’hypothèse selon laquelle un terme doit être à la fois fréquent et spécifique à un document pour caractériser ce dernier. Notons que cette feature est peu gourmande en termes de calcul.</p>
<p>Nous avons utilisé scikit-learn pour implémenter la classification. La feature est représentée par le vecteur TF-IDF et le classifieur utilisé est le classifieur bayésien. Nous avons utilisé un split de 0.3, ce qui fait qu’environ 300 articles par thème ont été utilisés comme test. Le random state a été configuré à 42 pour garantir la reproductibilité de notre travail.</p>
<p>Dans un premier temps nous avons essayé de classifier tous les 5 thèmes pour en sélectionner ceux qui présentent le plus de difficultés. La Figure 5 montre la performance du classifieur sur les articles de 5 thèmes :</p>
<p><img alt="" src="../_images/e6e2fd44.png"/></p>
<p>Figure 5 : Matrice de confusion du classifieur bayésien sur les articles de 5 thèmes</p>
<p>Le fait que les classes <code class="docutils literal notranslate"><span class="pre">économie,</span> <span class="pre">politique</span> <span class="pre">et</span> <span class="pre">société</span></code> sont les plus faciles à confondre pour le classifieur nous a décidés à choisir ces 3 thèmes pour notre projet. La Figure 6 rapporte les métriques principales à l’issue de cette sélection :</p>
<p><img alt="" src="../_images/12d5a6a6.png"/></p>
<p>Figure 6 : Métriques classiques pour la classification de textes sur les articles en 3 thèmes</p>
<p>Vous pouvez voir que la classe économie est la mieux classée et les deux autres présentent une plus grande confusion, ce qui est plutôt attendu car la classe économie renvoie à une notion plus restreinte.</p>
<p>Avec le package Lime nous avons pu voir comment est procédé le classifieur pour classer les articles, la Figure 7 montre l’exemple d’un seul article. L’interprétation de cette figure est plutôt intuitive : La légende d’en haut à gauche présente les probabilités respectives que cet article appartient aux 3 classes (la somme = 1). Lorsque le score se situe à droite, il contribue positivement à la classification.</p>
<p><img alt="" src="../_images/e1cb0478.png"/></p>
<p>Figure 7 : Contribution des termes à la classification d’un article</p>
<p>Les fonctionnalités proposées par Lime nous ont incités à faire un post-traitement susceptible d’augmenter la performance du classifieur. Nous avons extrait les 3 premiers termes de chaque prédiction de classe au cas où la prédiction serait mauvaise. Cette liste de termes constitue par la suite une liste de « mots inadéquats » avec laquelle nous filtrons le texte de chaque article. Nous avons ensuite ré-entraîné le classifieur, portant l’accuracy global de 0.82 à 0.85. Ce score de 0.85 a été retenu par la suite comme benchmark pour notre tâche de classification.</p>
</section>
<section id="classification-a-base-du-plongement-lexical">
<h3>Classification à base du plongement lexical<a class="headerlink" href="#classification-a-base-du-plongement-lexical" title="Permalink to this heading">¶</a></h3>
<p>Dans cette sous-section nous allons utiliser le plongement lexical pour caractériser un mot et par la suite un article en prenant la moyenne de tous les vecteurs lexicaux constituant l’article.</p>
<p>Le plongement lexical vise à représenter un mot par un vecteur de nombres réels. Autrement dit, le principe fondamental consiste à représenter un concept linguistique par l’intermédiaire d’une représentation mathématique. Le mot « chien » serait représenté par exemple par un vecteur à 3 dimensions [1.3, 2.2, 4,1].</p>
<p>Au cours de la recherche d’une représentation mathématique adéquate, certaines idées ont permis d’éclairer le chemin dont entre autres l’hypothèse distributionnelle de Harris (distributional hypothesis, (Harris, 1954)) dans le domaine de la sémantique distributionnelle. On retiendra aussi la fameuse phrase de Firth : Vous connaîtrez un mot par ses voisinages (You shall know a word by the company it keeps (Firth, 1957)). L’implémentation informatique la plus courante de cette idée est basée sur l’article de (Mikolov et al., 2013). Notons que le plongement lexical est en essence le produit d’une tâche reposant elle-même sur l’entraînement d’un réseau de neurones . Deux tâches sont possibles pour obtenir les vecteurs : soit on essaie de prédire un mot à partir de son contexte (CBOW), soit on prédit l’entourage d’un mot (Skip-gram).</p>
<p>Pour entraîner le modèle vectoriel nous avons utilisé différents corpus et différents paramètres. La Table 1 récapitule les informations pertinentes (Les deux modèles FrWac ont été téléchargés sur https://fauconnier.github.io/) :</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p><br/>Nom de modèle</p></th>
<th class="head"><p><br/>Méthode</p></th>
<th class="head"><p><br/>Dimension</p></th>
<th class="head"><p><br/>Corpus</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><br/>model_frWac_skip</p></td>
<td><p><br/>Skip-gram</p></td>
<td><p><br/>500</p></td>
<td><p><br/>FrWac</p></td>
</tr>
<tr class="row-odd"><td><p><br/>model_frWac</p></td>
<td><p><br/>CBOW</p></td>
<td><p><br/>500</p></td>
<td><p><br/>FrWac</p></td>
</tr>
<tr class="row-even"><td><p><br/>Model_1000_100dim<br/> <br/>Model_1000_200dim<br/> <br/>Model_1000_500dim<br/> <br/>Model_1000_1000dim</p></td>
<td><p><br/>CBOW</p></td>
<td><p><br/>100/200/500/1000</p></td>
<td><p><br/>3000 articles en 3 thèmes</p></td>
</tr>
<tr class="row-odd"><td><p><br/>Model_8000_100dim<br/> <br/>Model_8000_200dim<br/> <br/>Model_8000_500dim<br/> <br/>Model_8000_1000dim</p></td>
<td><p><br/>CBOW</p></td>
<td><p><br/>100/200/500/1000</p></td>
<td><p><br/>24000 articles en 3 thèmes</p></td>
</tr>
</tbody>
</table></div>
<p>Table 1 : Modèles vectoriels utilisés pour la classification de textes</p>
<p>Pour évaluer l’effet de modèle sur la performance de classification, nous avons commencé par utiliser la régression logistique qui aboutit à une décision binaire. Les résultats sont présentés dans la Table 2 :</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p><br/>Modèles</p></th>
<th class="head"><p><br/>Classes</p></th>
<th class="head"><p><br/>Performance (accuracy)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><br/>Model_1000_100dim<br/> <br/>Model_1000_200dim<br/> <br/>Model_1000_500dim<br/> <br/>model_1000_1000dim</p></td>
<td><p><br/>Économie vs politique</p></td>
<td><p><br/>0.87<br/> <br/>0.86<br/> <br/>0.86<br/> <br/>0.86</p></td>
</tr>
<tr class="row-odd"><td><p><br/>Model_8000_100dim<br/> <br/>Model_8000_200dim<br/> <br/>Model_8000_500dim<br/> <br/>model_8000_1000dim</p></td>
<td><p><br/>Économie vs politique</p></td>
<td><p><br/>0.92<br/> <br/>0.92<br/> <br/>0.90<br/> <br/>0.92</p></td>
</tr>
<tr class="row-even"><td><p><br/>Model_1000_100dim<br/> <br/>Model_1000_200dim<br/> <br/>Model_1000_500dim<br/> <br/>model_1000_1000dim</p></td>
<td><p><br/>Économie vs société</p></td>
<td><p><br/>0.82<br/> <br/>0.81<br/> <br/>0.81<br/> <br/>0.79</p></td>
</tr>
<tr class="row-odd"><td><p><br/>Model_8000_100dim<br/> <br/>Model_8000_200dim<br/> <br/>Model_8000_500dim<br/> <br/>model_8000_1000dim</p></td>
<td><p><br/>Économie vs société</p></td>
<td><p><br/>0.91<br/> <br/>0.92<br/> <br/>0.92<br/> <br/>0.91</p></td>
</tr>
<tr class="row-even"><td><p><br/>Model_1000_100dim<br/> <br/>Model_1000_200dim<br/> <br/>Model_1000_500dim<br/> <br/>model_1000_1000dim</p></td>
<td><p><br/>Politique vs société</p></td>
<td><p><br/>0.82<br/> <br/>0.78<br/> <br/>0.83<br/> <br/>0.79</p></td>
</tr>
<tr class="row-odd"><td><p><br/>Model_8000_100dim<br/> <br/>Model_8000_200dim<br/> <br/>Model_8000_500dim<br/> <br/>model_8000_1000dim</p></td>
<td><p><br/>Politique vs société</p></td>
<td><p><br/>0.84<br/> <br/>0.84<br/> <br/>0.81<br/> <br/>0.84</p></td>
</tr>
</tbody>
</table></div>
<p>Table 2 : Performance des classifieurs binaires en fonction du modèle vectoriel</p>
<p>Cette table nous permet de faire deux remarques :</p>
<ol class="simple">
<li><p>l’augmentation de la dimensionnalité ne s’accompagne pas d’une augmentation de performance.</p></li>
<li><p>l’augmentation du nombre d’articles augmente la performance des vecteurs dans la tâche de classification. Cependant nous pouvons voir que l’accuracy des classes politique et société reste bas et le changement de modèle aussi bien sur le plan dimensionnel que sur le plan du nombre d’articles, apporte un gain de performance plus faible par rapport à d’autres combinaisons de classes.</p></li>
</ol>
<p>Nous utilisons ensuite divers classifieurs multi-classes (onevsRest, kNeighbors, SVM, Bayésien, Perceptron multicouche, etc.) pour mener la même comparaison de modèles, sans inclure l’effet de dimensionnalité.</p>
<p>Nous présentons ici que les meilleurs résultats obtenus par SVM car le but de ce travail n’est pas d’étudier les différences d’algorithmes, d’autant plus qu’il existe aujourd’hui un champ d’études appelé automated machine learning qui permet de chercher automatiquement le meilleur algorithme avec les meilleurs paramètres pour une tâche donnée.</p>
<p>La Table 3 récapitule les résultats :</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p><br/>Modèles</p></th>
<th class="head"><p><br/>Dimension</p></th>
<th class="head"><p><br/>Performance (accuracy)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><br/>Model_1000_100dim<br/> <br/></p></td>
<td><p><br/>500</p></td>
<td><p><br/>0.74</p></td>
</tr>
<tr class="row-odd"><td><p><br/>Model_8000_100dim<br/> <br/></p></td>
<td><p><br/>500</p></td>
<td><p><br/>0.82<br/> <br/></p></td>
</tr>
<tr class="row-even"><td><p><br/>Modèle frWac<br/> <br/>model_frWac_skip<br/> <br/></p></td>
<td><p><br/>500</p></td>
<td><p><br/>0.81<br/> <br/>0.80<br/> <br/></p></td>
</tr>
</tbody>
</table></div>
<p>Table 3 : Performance des classifieurs multi-classes en fonction du modèle vectoriel</p>
<p>L’importance du corpus pour l’entraînement des vecteurs mérite d’être soulignée. En augmentant le nombre d’articles de 3000 à 24000, l’accuracy est passé de 0.74 à 0.82, dépassant le score du modèle FrWac entraîné sur 1.6 milliards de mots. Cela montre qu’un corpus spécifique est important et ce corpus peut s’avérer plus pertinent qu’un corpus de grande taille pour la tâche de classification de textes.</p>
<p>Cependant, les F1 scores des classes politique et société restent bas. Ils sont respectivement 0.75 et 0.76, ce qui fait que l’accuracy général du classifieur SVM est inférieur au benchmark TF-IDF (0.82 vs 0.85).</p>
</section>
<section id="elaboration-des-features-dites-expertes">
<h3>Elaboration des features dites expertes<a class="headerlink" href="#elaboration-des-features-dites-expertes" title="Permalink to this heading">¶</a></h3>
<p>Pour améliorer davantage notre classifieur SVM, nous avons calculé 5 features supplémentaires : diversité lexicale, distance cosinus entre un article et 4 termes les plus fréquents à chaque classe et enfin, un vecteur one-hot à 12 dimensions construit sur l’absence et la présence des 4 termes mentionnés plus haut. La diversité lexicale a été calculée en divisant le nombre de tokens uniques par le nombre de tokens total.</p>
<p>Pour évaluer l’effet de chaque feature, nous avons tout d’abord exclu le vecteur du document et utilisé la régression logistique (méthode Newton-conjugate gradient) en gardant uniquement les features expertes. Les valeurs P&gt;|z| nous indiquent que la diversité lexicale est peu probable de contribuer à la classification (0.986). En revanche, les distances cosinus et le vecteur one-hot sont tous pertinents (toutes les valeurs sont inférieures à 0.05).</p>
<p>Nous avons donc intégré ces deux features dans le classifieur SVM. L’accuracy général est monté à 0.85 et les F1 scores montés à 0.80 pour les classes politique et société.</p>
</section>
</section>
<section id="conclusions-et-perspectives">
<h2>Conclusions et perspectives<a class="headerlink" href="#conclusions-et-perspectives" title="Permalink to this heading">¶</a></h2>
<p>Nous avons donc construit un corpus de 5 thèmes, appliqué un prétraitement typique sur les textes de chaque article, extrait et élaboré des features et enfin testé les features sur divers classifieurs.</p>
<p>Quelques points méritent d’être mentionnés :</p>
<ol class="simple">
<li><p>L’efficacité du plongement lexical est relativement indépendante du nombre de dimensions dans la tâche de classification de textes. En revanche, la taille du corpus est importante ainsi que la nature du corpus. Les vecteurs entraînés sur le corpus de 24000 articles ont atteint quasiment la même performance que les vecteurs entraînés sur le corpus FrWac.</p></li>
<li><p>Les features expertes sont utiles pour augmenter la performance de classification. Cela met en évidence l’importance des connaissances spécifiques au domaine (Domain-Specific Knowledge).</p></li>
<li><p>Lime permet d’expliquer les méthodes de machine learning et d’améliorer la performance des méthodes. Dans la section 4.1, nous avons montré que la suppression des mots non pertinents à la classification permet d’augmenter l’accuracy de 0.82 à 0.85.</p></li>
</ol>
</section>
<section id="tutoriels-a-venir">
<h2>Tutoriels à venir<a class="headerlink" href="#tutoriels-a-venir" title="Permalink to this heading">¶</a></h2>
<p>Dans le domaine de la classification de textes, les réseaux de neurones du type RNN ont fait preuve d’efficacité. Des modèles de langues pré-entraînés du type Bert (Vaswani et al., 2017) ont davantage poussé les limites de performance. Des features linguistiques basés sur les propriétés morpho-syntaxiques des tokens peuvent aussi s’avérer utiles.</p>
<p>A très bientôt pour plus de tutoriels :D</p>
</section>
<section id="references">
<h2>Références<a class="headerlink" href="#references" title="Permalink to this heading">¶</a></h2>
<p>Fauconnier, J.-P. (2015). French word embeddings.</p>
<p>Firth, J. R. (1957). A synopsis of linguistic theory, 1930-1955. Studies in Linguistic Analysis.</p>
<p>Harris, Z. S. (1954). Distributional structure. Word, 10(2–3), 146–162.</p>
<p>Mikolov, T., Chen, K., Corrado, G., &amp; Dean, J. (2013). Efficient estimation of word representations in vector space. ArXiv Preprint ArXiv:1301.3781
.
Qi, P., Zhang, Y., Zhang, Y., Bolton, J., &amp; Manning, C. D. (2020). Stanza: A Python natural language processing toolkit for many human languages. ArXiv Preprint ArXiv:2003.07082
.
Ribeiro, M. T., Singh, S., &amp; Guestrin, C. (2016). “Why Should I Trust You?”: Explaining the Predictions of Any Classifier. ArXiv:1602.04938 [Cs, Stat]. http://arxiv.org/abs/1602.04938</p>
<p>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., &amp; Polosukhin, I. (2017). Attention is all you need. ArXiv Preprint ArXiv:1706.03762.</p>
</section>
</section>

      </article>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../transformers/index.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Transformers in NLP with PyTorch, TensorFlow and Hugging Face</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="02_classification_prenoms_fr.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Classification de prénoms en genre (masculin/féminin) 🇫🇷</div>
                
              </div>
            </a>
        </div>

        <div class="related-information">
              Copyright &#169; 2022, Xiaoou Wang
            |
            Built with <a href="https://www.sphinx-doc.org/">Sphinx</a>
              and
              <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
              <a href="https://github.com/pradyunsg/furo">Furo theme</a>.
            |
            <a class="muted-link" href="../sources/nlp/03_classification_lemonde_fr.md.txt"
               rel="nofollow">
              Show Source
            </a>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Text Classification: du TF-IDF aux word embeddings en passant par features expertes 🇫🇷</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#structure-du-tutoriel">Structure du tutoriel</a></li>
<li><a class="reference internal" href="#pretraitement-du-corpus">Prétraitement du corpus</a></li>
<li><a class="reference internal" href="#classification-de-textes">Classification de textes</a><ul>
<li><a class="reference internal" href="#etablissement-dune-baseline">Établissement d’une baseline</a></li>
<li><a class="reference internal" href="#classification-a-base-du-plongement-lexical">Classification à base du plongement lexical</a></li>
<li><a class="reference internal" href="#elaboration-des-features-dites-expertes">Elaboration des features dites expertes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conclusions-et-perspectives">Conclusions et perspectives</a></li>
<li><a class="reference internal" href="#tutoriels-a-venir">Tutoriels à venir</a></li>
<li><a class="reference internal" href="#references">Références</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </main>
</div>
    <script id="documentation_options" data-url_root="../" src="../static/documentation_options.js"></script>
    <script data-url_root="../" id="documentation_options" src="../static/documentation_options.js"></script>
    <script src="../static/doctools.js"></script>
    <script src="../static/sphinx_highlight.js"></script>
    <script src="../static/clipboard.min.js"></script>
    <script src="../static/copybutton.js"></script>
    <script src="../static/tabs.js"></script>
    <script>
</script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" />
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-58WGY2PHYB"></script>
<script src='https://kit.fontawesome.com/a076d05399.js' crossorigin='anonymous'></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-58WGY2PHYB');
</script>
<!-- Default Statcounter code for nlpinfrench
http://nlpinfrench.fr -->
<script type="text/javascript">
var sc_project=12500373;
var sc_invisible=1;
var sc_security="def60251";
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics
Made Easy - StatCounter" href="https://statcounter.com/"
target="_blank"><img class="statcounter"
src="https://c.statcounter.com/12500373/0/def60251/1/"
alt="Web Analytics Made Easy -
StatCounter"></a></div></noscript>
<!-- End of Statcounter Code -->
<script src="https://cdn.jsdelivr.net/gh/cferdinandi/gumshoe@4.0/dist/gumshoe.polyfills.min.js"></script>
</script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../static/custom.js"></script>
    <script src="../static/scripts/main.js?digest=e931d09b2a40c1bb82b542effe772014573baf67"></script></body>
</html>
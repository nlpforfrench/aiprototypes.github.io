<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Transformers in NLP with PyTorch, TensorFlow and Hugging Face" href="../transformers/index.html" /><link rel="prev" title="Classification de prÃ©noms en genre (masculin/fÃ©minin) ğŸ‡«ğŸ‡·" href="02_classification_prenoms_fr.html" />

    <meta name="generator" content="sphinx-6.1.3, furo 2021.02.28.beta28"/>
        <title>Text Classification: du TF-IDF aux word embeddings en passant par features expertes ğŸ‡«ğŸ‡· - </title>
      <link rel="stylesheet" href="../static/styles/furo.css?digest=be5985a4059b5c2cd56ed0804790452beca62674">
    <link rel="stylesheet" href="../static/pygments.css">
    <link media="(prefers-color-scheme: dark)" rel="stylesheet" href="../static/pygments_dark.css">
    


<style>
  :root {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media (prefers-color-scheme: dark) {
    :root {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
  }

  /* For allowing end-user-specific overrides */
  .override-light {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  .override-dark {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
  }
</style><link rel="stylesheet" type="text/css" href="../static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../static/styles/furo.css" />
    <link rel="stylesheet" type="text/css" href="../static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../static/custom.css" />
    <link rel="stylesheet" href="../static/styles/furo-extensions.css?digest=d391b54134226e4196576da3bdb6dddb7e05ba2b"></head>
  <body dir="">
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke-width="1.5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z"/>
      <line x1="4" y1="6" x2="20" y2="6" />
      <line x1="10" y1="12" x2="20" y2="12" />
      <line x1="6" y1="18" x2="20" y2="18" />
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand"></div></a>
    </div>
    <div class="header-right">
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text"></span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html">
  <input class="sidebar-search" placeholder=Search name="q">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">NLP and Machine Learning-related</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label for="toctree-checkbox-1"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_compara_anno_fr.html">Comparer Spacy, StanfordNLP et TreeTagger sur un corpus oral et un corpus de presse ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_classification_prenoms_fr.html">Classification de prÃ©noms en genre (masculin/fÃ©minin) ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Text Classification: du TF-IDF aux word embeddings en passant par features expertes ğŸ‡«ğŸ‡·</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../transformers/index.html">Transformers in NLP with PyTorch, TensorFlow and Hugging Face</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label for="toctree-checkbox-2"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../transformers/01_theorie_en.html">10 questions on Bert ğŸ‡¬ğŸ‡§</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transformers/01_theorie_fr.html">10 questions sur Bert ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transformers/02_firstBert_fr.html">Classification de commentaires avec Camembert sans prise de tÃªte : les fondamentaux ğŸ‡«ğŸ‡·</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../better_programmer/index.html">Better Programmer</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label for="toctree-checkbox-3"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/01_python_fr.html">Mieux programmer en Python ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/02_git3_en.html">A serious guide to git ğŸ‡¬ğŸ‡§</a></li>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/03_jupyter_remote_pycharm.html">Connect to remote jupyter notebook in Pycharm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/04_oop_web_scraping_en.html">Understand objected-oriented programming (OOP) by building a minimal Web Scraping framework ğŸ‡¬ğŸ‡§</a></li>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/05_oop_web_scraping_cooper_en.html">Be a responsible programmer when doing Object-Oriented Programming ğŸ‡¬ğŸ‡§</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../algo/index.html">Algorithms and data structures by examples in Python</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label for="toctree-checkbox-4"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../algo/01_intro_en.html">Algorithm or many ways of solving a problem ğŸ‡¬ğŸ‡§</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/01_intro_fr.html">Algorithme ou plusieurs faÃ§ons de rÃ©soudre un problÃ¨me ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/02_ds_en.html">Data structures or many ways of organizing your stuff ğŸ‡¬ğŸ‡§</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/099algo_map.html">Roadmap and cheatsheet of algorithms and data structures</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../web/index.html">Web Related</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label for="toctree-checkbox-5"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../web/01_lemonde_en.html">Complete tutorial on scraping French news from Le Monde ğŸ‡¬ğŸ‡§</a></li>
<li class="toctree-l2"><a class="reference internal" href="../web/01_lemonde_fr.html">Scraper Â« le monde Â» et construire ton propre corpus ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../web/02_forum_en.html">On your way to scraping French forums ğŸ‡¬ğŸ‡§</a></li>
<li class="toctree-l2"><a class="reference internal" href="../web/03_django_en.html">Deploying Django app on Ubuntu at digitalocean + SSL certificate ğŸ‡¬ğŸ‡§</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../linguistique_informatique/index.html">Computational Linguistics in R</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label for="toctree-checkbox-6"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../linguistique_informatique/01_zipf_fr.html">La loi de Zipf illustrÃ©e avec gutenbergr en R ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linguistique_informatique/02_mca_ergatif_fr.html">Analyse des Correspondances Multiples : le cas de lâ€™ergatif en warlipiri ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linguistique_informatique/03_pca_inclusion_fr.html">Analyse en composantes principales (PCA) : prÃ©positions dâ€™inclusion en franÃ§ais ğŸ‡«ğŸ‡·</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../high_performance_python/index.html">High performance computing</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label for="toctree-checkbox-7"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../high_performance_python/01_parallel_primer_en.html">Parallelization in Python: a beginnerâ€™s guide (1, using map)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../codebase/index.html">My Codebase</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label for="toctree-checkbox-8"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../codebase/01_bash.html">My codebase for bash/shell script (macOS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../codebase/02_tmux.html">Tumux-related code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../codebase/03_python.html">My python codebase (including packages/libraries)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../codebase/05_pytorch.html">Pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../codebase/06_pandas.html">Pandas codebase</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../math/index.html">Mathematics in Machine Learning and NLP</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label for="toctree-checkbox-9"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../math/01_math_fr.html">Machine Learning : algorithmes et mathÃ©matiques ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/01_math_fr.html">Machine Learning : algorithmes et mathÃ©matiques ğŸ‡«ğŸ‡·</a></li>
</ul>
</li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <main class="main">
    <div class="content">
      <article role="main">
        <label class="toc-overlay-icon toc-content-icon" for="__toc">
          <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
        </label>
        <section id="text-classification-du-tf-idf-aux-word-embeddings-en-passant-par-features-expertes">
<h1>Text Classification: du TF-IDF aux word embeddings en passant par features expertes ğŸ‡«ğŸ‡·<a class="headerlink" href="#text-classification-du-tf-idf-aux-word-embeddings-en-passant-par-features-expertes" title="Permalink to this heading">Â¶</a></h1>
<p><a class="reference external" href="https://scholar.google.fr/citations?user=vKAMMpwAAAAJ&amp;hl=en">Xiaoou WANG</a>, <a class="reference external" href="https://www.linkedin.com/in/xingyu-liu-aba896a1/">Xingyu LIU</a></p>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">Â¶</a></h2>
<p>La classification de textes est une tÃ¢che courante en traitement automatique des langues (TAL). Dans ce tutoriel nous allons explorer diverses features (TF-IDF, plongement lexical, features linguistiques) alimentant Ã  leur tour des modÃ¨les variÃ©s dont entre autres la rÃ©gression logistique, classification naÃ¯ve bayÃ©sienne et perceptron multicouche.</p>
<p>Le but de ce tutoriel est de construire un classifieur qui permet de catÃ©goriser correctement des textes en 3 classes : sociÃ©tÃ©, Ã©conomie et politique.</p>
<div class="admonition-teaser admonition">
<p class="admonition-title">Teaser</p>
<p>ExclusivitÃ©s :D</p>
</div>
<ol class="simple">
<li><p>Le corpus a Ã©tÃ© construit grÃ¢ce au site des archives de Â« le monde Â». Regardez <span class="xref myst">ici</span> pour un tutoriel rapide.</p></li>
<li><p>Une mise en parallÃ¨le a Ã©tÃ© soigneusement construite pour montrer lâ€™efficacitÃ© des vecteurs lexicaux entraÃ®nÃ©s sur un corpus spÃ©cifique qui atteint la mÃªme performance dâ€™un modÃ¨le Ã  partir du corpus frWac de 1.6 milliards de mots  (Fauconnier, 2015).</p></li>
<li><p>Le package Lime (Ribeiro et al., 2016) a Ã©tÃ© utilisÃ© pour comprendre et par la suite amÃ©liorer les features.</p></li>
<li><p>Quelques features linguistiques dites expertes ont Ã©tÃ© construites pour amÃ©liorer la performance de classification suite Ã  une sÃ©lection manuelle sâ€™appuyant sur la rÃ©gression logistique.</p></li>
<li><p>Ce tutoriel est un issu dâ€™un travail dâ€™Ã©quipe, nous avons veillÃ© au bon dÃ©roulement et Ã  la bonne rÃ©partition des tÃ¢ches en mettant en place toute une panoplie dâ€™outils en logistique comme <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">mÃ©thode</span> <span class="pre">agile</span></code>, <a class="reference external" href="https://github.com/xiaoouwang/tuto_classification">Github</a>, <code class="docutils literal notranslate"><span class="pre">Omniplan</span></code> (outil de gestion de projet) et un document <a class="reference external" href="https://docs.google.com/document/d/11vaB74HV0GxerkVm9Pv_mgnhXN27QVegFYPdPA34t5g/edit?usp=sharing">Google Docs</a> auquel vous pouvez vous rÃ©fÃ©rer pour revoir comment ce tutoriel dâ€™Ã©quipe a Ã©tÃ© rÃ©alisÃ© pendant plus dâ€™un mois.</p></li>
</ol>
<p>La rÃ©partition des tÃ¢ches est illustrÃ©e succinctement par la Figure 1 :</p>
<p><img alt="" src="../_images/ac2e3489.png"/></p>
<p>Figure 1 : RÃ©partition des tÃ¢ches pendant lâ€™Ã©criture de ce tutoriel</p>
</section>
<section id="structure-du-tutoriel">
<h2>Structure du tutoriel<a class="headerlink" href="#structure-du-tutoriel" title="Permalink to this heading">Â¶</a></h2>
<ol class="simple">
<li><p>Nous prÃ©sentons le prÃ©traitement de notre corpus.</p></li>
<li><p>Ensuite nous utilisons TF-IDF comme feature et un classifieur bayÃ©sien pour Ã©tablir une baseline. Le package <code class="docutils literal notranslate"><span class="pre">Lime</span></code> est utilisÃ© pour comprendre le fonctionnement du classifieur qui a ensuite permis une lÃ©gÃ¨re amÃ©lioration de performance.</p></li>
<li><p>La baseline Ã©tablie, divers modÃ¨les vectoriels sont entraÃ®nÃ©s sur des corpus de diffÃ©rentes tailles en utilisant diffÃ©rents paramÃ¨tres. Cela nous a permis dâ€™Ã©tudier les effets des paramÃ¨tres et de la taille du corpus dâ€™entraÃ®nement.</p></li>
<li><p>Enfin pour davantage augmenter la prÃ©cision de classification nous introduisons quelques features linguistiques expertes, ces derniÃ¨res Ã©tant soumises Ã  un test basÃ© sur la rÃ©gression logistique pour que les features les plus pertinentes puissent Ãªtre mises en avant.</p></li>
</ol>
</section>
<section id="pretraitement-du-corpus">
<h2>PrÃ©traitement du corpus<a class="headerlink" href="#pretraitement-du-corpus" title="Permalink to this heading">Â¶</a></h2>
<p>Nous avons scrapÃ© 9000 articles par thÃ¨me. Les thÃ¨mes principaux sont : sociÃ©tÃ©, sport, Ã©conomie, culture et politique. Nous avons ensuite sÃ©lectionnÃ© alÃ©atoirement 1000 articles pour la tÃ¢che de classification.</p>
<p>La tokenisation a Ã©tÃ© effectuÃ©e avec le package Stanza (Qi et al., 2020). Ce tokeniseur a notamment lâ€™avantage de regrouper par dÃ©faut des mots sÃ©parÃ©s par tiret du type Â« gratte-ciel Â», alors que dans Spacy un tel comportement nÃ©cessite une configuration ad hoc engendrant dâ€™autres problÃ¨mes.</p>
<p>Nous avons aussi essayÃ© de regrouper les entitÃ©s nommÃ©es dans un seul token car cela permet de garder des informations sÃ©mantiques intactes. Dans Spacy il est facile dâ€™y procÃ©der ainsi mais dans Stanza il nâ€™existe pas de fonction prÃ©-dÃ©finie. Nous avons donc soumis un <a class="reference external" href="https://github.com/stanfordnlp/stanza/issues/583">issue</a> sur Github et proposÃ© notre propre solution sur le mÃªme lien au cas oÃ¹ cela pourrait servir la communautÃ©.</p>
<p>Ensuite nous avons lemmatisÃ© les tokens et enlevÃ© les mots vides et ponctuation. Pour la liste des mots vides nous avons combinÃ© les ensembles proposÃ©s par <code class="docutils literal notranslate"><span class="pre">NLTK</span></code> et <code class="docutils literal notranslate"><span class="pre">Spacy</span></code>. Notons que cette Ã©tape, en enlevant les tokens peu pertinents Ã  chaque document, constitue en essence une tentative de rÃ©duction de dimensionnalitÃ©.</p>
<p>Enfin nous avons mis tous les tokens en minuscules. Lâ€™ensemble des opÃ©rations est illustrÃ© par la Figure 2 :</p>
<p><img alt="" src="../_images/768a8e62.png"/></p>
<p>Figure 2 : PrÃ©traitement en amont des articles en vue de la classification</p>
<p>Notons que nous avons aussi prÃ©parÃ© une version enrichie du corpus en xml pour calculer des features expertes. Il y a en tout 6 colonnes signifiant id, token, lemme, partie du discours, tÃªte et relation de dÃ©pendance. Par contraintes dâ€™espace nous ne dÃ©taillons pas la procÃ©dure de prÃ©paration. Chaque article est enchÃ¢ssÃ© dans le tag <code class="docutils literal notranslate"><span class="pre">&lt;art&gt;</span></code> avec label comme attribut et classe comme valeur. Ensuite chaque phrase est contenue dans un tag <code class="docutils literal notranslate"><span class="pre">&lt;s&gt;</span></code>. La Figure 3 montre la structure du fichier xml :</p>
<p><img alt="" src="../_images/c6849494.png"/></p>
<p>Figure 3 : Structure du corpus enrichi en xml</p>
</section>
<section id="classification-de-textes">
<h2>Classification de textes<a class="headerlink" href="#classification-de-textes" title="Permalink to this heading">Â¶</a></h2>
<section id="etablissement-dune-baseline">
<h3>Ã‰tablissement dâ€™une baseline<a class="headerlink" href="#etablissement-dune-baseline" title="Permalink to this heading">Â¶</a></h3>
<p>Vu que notre classifieur recourra principalement au plongement lexical, il nous a paru utile dâ€™Ã©tablir une baseline en utilisant un vecteur TF-IDF.</p>
<p>Un document peut Ãªtre reprÃ©sentÃ© de diverses faÃ§ons selon le traitement des mots contenus dans le document. Le modÃ¨le le plus simple est le sac de mots qui compte lâ€™occurrence de chaque token afin de gÃ©nÃ©rer une matrice documents-termes (MDT). Ce modÃ¨le est quelque peu simpliste car lâ€™occurrence des tokens augmente en fonction de la longueur du document. Pour remÃ©dier Ã  ce dÃ©faut la MDT peut Ãªtre modifiÃ©e pour reprÃ©senter non plus la frÃ©quence absolue mais la frÃ©quence relative des tokens. Cependant il subsiste toujours le problÃ¨me des mots vides car ces derniers sont quasiment toujours les plus frÃ©quents (cf. la loi de Zipf Ã  ce propos).</p>
<p>Pour faire face Ã  ce problÃ¨me une autre mesure est proposÃ©e : celle de TF-IDF, la formule de cette mesure est la suivante :</p>
<figure class="align-center" id="id1">
<img alt="../_images/a322e8b3.png" src="../_images/a322e8b3.png"/>
<figcaption>
<p><span class="caption-text">Figure 4 : Formule de TF-IDF</span><a class="headerlink" href="#id1" title="Permalink to this image">Â¶</a></p>
</figcaption>
</figure>
<p>Lâ€™efficacitÃ© de cette mesure est basÃ©e sur lâ€™hypothÃ¨se selon laquelle un terme doit Ãªtre Ã  la fois frÃ©quent et spÃ©cifique Ã  un document pour caractÃ©riser ce dernier. Notons que cette feature est peu gourmande en termes de calcul.</p>
<p>Nous avons utilisÃ© scikit-learn pour implÃ©menter la classification. La feature est reprÃ©sentÃ©e par le vecteur TF-IDF et le classifieur utilisÃ© est le classifieur bayÃ©sien. Nous avons utilisÃ© un split de 0.3, ce qui fait quâ€™environ 300 articles par thÃ¨me ont Ã©tÃ© utilisÃ©s comme test. Le random state a Ã©tÃ© configurÃ© Ã  42 pour garantir la reproductibilitÃ© de notre travail.</p>
<p>Dans un premier temps nous avons essayÃ© de classifier tous les 5 thÃ¨mes pour en sÃ©lectionner ceux qui prÃ©sentent le plus de difficultÃ©s. La Figure 5 montre la performance du classifieur sur les articles de 5 thÃ¨mes :</p>
<p><img alt="" src="../_images/e6e2fd44.png"/></p>
<p>Figure 5 : Matrice de confusion du classifieur bayÃ©sien sur les articles de 5 thÃ¨mes</p>
<p>Le fait que les classes <code class="docutils literal notranslate"><span class="pre">Ã©conomie,</span> <span class="pre">politique</span> <span class="pre">et</span> <span class="pre">sociÃ©tÃ©</span></code> sont les plus faciles Ã  confondre pour le classifieur nous a dÃ©cidÃ©s Ã  choisir ces 3 thÃ¨mes pour notre projet. La Figure 6 rapporte les mÃ©triques principales Ã  lâ€™issue de cette sÃ©lection :</p>
<p><img alt="" src="../_images/12d5a6a6.png"/></p>
<p>Figure 6 : MÃ©triques classiques pour la classification de textes sur les articles en 3 thÃ¨mes</p>
<p>Vous pouvez voir que la classe Ã©conomie est la mieux classÃ©e et les deux autres prÃ©sentent une plus grande confusion, ce qui est plutÃ´t attendu car la classe Ã©conomie renvoie Ã  une notion plus restreinte.</p>
<p>Avec le package Lime nous avons pu voir comment est procÃ©dÃ© le classifieur pour classer les articles, la Figure 7 montre lâ€™exemple dâ€™un seul article. Lâ€™interprÃ©tation de cette figure est plutÃ´t intuitive : La lÃ©gende dâ€™en haut Ã  gauche prÃ©sente les probabilitÃ©s respectives que cet article appartient aux 3 classes (la somme = 1). Lorsque le score se situe Ã  droite, il contribue positivement Ã  la classification.</p>
<p><img alt="" src="../_images/e1cb0478.png"/></p>
<p>Figure 7 : Contribution des termes Ã  la classification dâ€™un article</p>
<p>Les fonctionnalitÃ©s proposÃ©es par Lime nous ont incitÃ©s Ã  faire un post-traitement susceptible dâ€™augmenter la performance du classifieur. Nous avons extrait les 3 premiers termes de chaque prÃ©diction de classe au cas oÃ¹ la prÃ©diction serait mauvaise. Cette liste de termes constitue par la suite une liste de Â« mots inadÃ©quats Â» avec laquelle nous filtrons le texte de chaque article. Nous avons ensuite rÃ©-entraÃ®nÃ© le classifieur, portant lâ€™accuracy global de 0.82 Ã  0.85. Ce score de 0.85 a Ã©tÃ© retenu par la suite comme benchmark pour notre tÃ¢che de classification.</p>
</section>
<section id="classification-a-base-du-plongement-lexical">
<h3>Classification Ã  base du plongement lexical<a class="headerlink" href="#classification-a-base-du-plongement-lexical" title="Permalink to this heading">Â¶</a></h3>
<p>Dans cette sous-section nous allons utiliser le plongement lexical pour caractÃ©riser un mot et par la suite un article en prenant la moyenne de tous les vecteurs lexicaux constituant lâ€™article.</p>
<p>Le plongement lexical vise Ã  reprÃ©senter un mot par un vecteur de nombres rÃ©els. Autrement dit, le principe fondamental consiste Ã  reprÃ©senter un concept linguistique par lâ€™intermÃ©diaire dâ€™une reprÃ©sentation mathÃ©matique. Le mot Â« chien Â» serait reprÃ©sentÃ© par exemple par un vecteur Ã  3 dimensions [1.3, 2.2, 4,1].</p>
<p>Au cours de la recherche dâ€™une reprÃ©sentation mathÃ©matique adÃ©quate, certaines idÃ©es ont permis dâ€™Ã©clairer le chemin dont entre autres lâ€™hypothÃ¨se distributionnelle de Harris (distributional hypothesis, (Harris, 1954)) dans le domaine de la sÃ©mantique distributionnelle. On retiendra aussi la fameuse phrase de Firth : Vous connaÃ®trez un mot par ses voisinages (You shall know a word by the company it keeps (Firth, 1957)). Lâ€™implÃ©mentation informatique la plus courante de cette idÃ©e est basÃ©e sur lâ€™article de (Mikolov et al., 2013). Notons que le plongement lexical est en essence le produit dâ€™une tÃ¢che reposant elle-mÃªme sur lâ€™entraÃ®nement dâ€™un rÃ©seau de neurones . Deux tÃ¢ches sont possibles pour obtenir les vecteurs : soit on essaie de prÃ©dire un mot Ã  partir de son contexte (CBOW), soit on prÃ©dit lâ€™entourage dâ€™un mot (Skip-gram).</p>
<p>Pour entraÃ®ner le modÃ¨le vectoriel nous avons utilisÃ© diffÃ©rents corpus et diffÃ©rents paramÃ¨tres. La Table 1 rÃ©capitule les informations pertinentes (Les deux modÃ¨les FrWac ont Ã©tÃ© tÃ©lÃ©chargÃ©s sur https://fauconnier.github.io/) :</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p><br/>Nom de modÃ¨le</p></th>
<th class="head"><p><br/>MÃ©thode</p></th>
<th class="head"><p><br/>Dimension</p></th>
<th class="head"><p><br/>Corpus</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><br/>model_frWac_skip</p></td>
<td><p><br/>Skip-gram</p></td>
<td><p><br/>500</p></td>
<td><p><br/>FrWac</p></td>
</tr>
<tr class="row-odd"><td><p><br/>model_frWac</p></td>
<td><p><br/>CBOW</p></td>
<td><p><br/>500</p></td>
<td><p><br/>FrWac</p></td>
</tr>
<tr class="row-even"><td><p><br/>Model_1000_100dim<br/> <br/>Model_1000_200dim<br/> <br/>Model_1000_500dim<br/> <br/>Model_1000_1000dim</p></td>
<td><p><br/>CBOW</p></td>
<td><p><br/>100/200/500/1000</p></td>
<td><p><br/>3000 articles en 3 thÃ¨mes</p></td>
</tr>
<tr class="row-odd"><td><p><br/>Model_8000_100dim<br/> <br/>Model_8000_200dim<br/> <br/>Model_8000_500dim<br/> <br/>Model_8000_1000dim</p></td>
<td><p><br/>CBOW</p></td>
<td><p><br/>100/200/500/1000</p></td>
<td><p><br/>24000 articles en 3 thÃ¨mes</p></td>
</tr>
</tbody>
</table></div>
<p>Table 1 : ModÃ¨les vectoriels utilisÃ©s pour la classification de textes</p>
<p>Pour Ã©valuer lâ€™effet de modÃ¨le sur la performance de classification, nous avons commencÃ© par utiliser la rÃ©gression logistique qui aboutit Ã  une dÃ©cision binaire. Les rÃ©sultats sont prÃ©sentÃ©s dans la Table 2 :</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p><br/>ModÃ¨les</p></th>
<th class="head"><p><br/>Classes</p></th>
<th class="head"><p><br/>Performance (accuracy)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><br/>Model_1000_100dim<br/> <br/>Model_1000_200dim<br/> <br/>Model_1000_500dim<br/> <br/>model_1000_1000dim</p></td>
<td><p><br/>Ã‰conomie vs politique</p></td>
<td><p><br/>0.87<br/> <br/>0.86<br/> <br/>0.86<br/> <br/>0.86</p></td>
</tr>
<tr class="row-odd"><td><p><br/>Model_8000_100dim<br/> <br/>Model_8000_200dim<br/> <br/>Model_8000_500dim<br/> <br/>model_8000_1000dim</p></td>
<td><p><br/>Ã‰conomie vs politique</p></td>
<td><p><br/>0.92<br/> <br/>0.92<br/> <br/>0.90<br/> <br/>0.92</p></td>
</tr>
<tr class="row-even"><td><p><br/>Model_1000_100dim<br/> <br/>Model_1000_200dim<br/> <br/>Model_1000_500dim<br/> <br/>model_1000_1000dim</p></td>
<td><p><br/>Ã‰conomie vs sociÃ©tÃ©</p></td>
<td><p><br/>0.82<br/> <br/>0.81<br/> <br/>0.81<br/> <br/>0.79</p></td>
</tr>
<tr class="row-odd"><td><p><br/>Model_8000_100dim<br/> <br/>Model_8000_200dim<br/> <br/>Model_8000_500dim<br/> <br/>model_8000_1000dim</p></td>
<td><p><br/>Ã‰conomie vs sociÃ©tÃ©</p></td>
<td><p><br/>0.91<br/> <br/>0.92<br/> <br/>0.92<br/> <br/>0.91</p></td>
</tr>
<tr class="row-even"><td><p><br/>Model_1000_100dim<br/> <br/>Model_1000_200dim<br/> <br/>Model_1000_500dim<br/> <br/>model_1000_1000dim</p></td>
<td><p><br/>Politique vs sociÃ©tÃ©</p></td>
<td><p><br/>0.82<br/> <br/>0.78<br/> <br/>0.83<br/> <br/>0.79</p></td>
</tr>
<tr class="row-odd"><td><p><br/>Model_8000_100dim<br/> <br/>Model_8000_200dim<br/> <br/>Model_8000_500dim<br/> <br/>model_8000_1000dim</p></td>
<td><p><br/>Politique vs sociÃ©tÃ©</p></td>
<td><p><br/>0.84<br/> <br/>0.84<br/> <br/>0.81<br/> <br/>0.84</p></td>
</tr>
</tbody>
</table></div>
<p>Table 2 : Performance des classifieurs binaires en fonction du modÃ¨le vectoriel</p>
<p>Cette table nous permet de faire deux remarques :</p>
<ol class="simple">
<li><p>lâ€™augmentation de la dimensionnalitÃ© ne sâ€™accompagne pas dâ€™une augmentation de performance.</p></li>
<li><p>lâ€™augmentation du nombre dâ€™articles augmente la performance des vecteurs dans la tÃ¢che de classification. Cependant nous pouvons voir que lâ€™accuracy des classes politique et sociÃ©tÃ© reste bas et le changement de modÃ¨le aussi bien sur le plan dimensionnel que sur le plan du nombre dâ€™articles, apporte un gain de performance plus faible par rapport Ã  dâ€™autres combinaisons de classes.</p></li>
</ol>
<p>Nous utilisons ensuite divers classifieurs multi-classes (onevsRest, kNeighbors, SVM, BayÃ©sien, Perceptron multicouche, etc.) pour mener la mÃªme comparaison de modÃ¨les, sans inclure lâ€™effet de dimensionnalitÃ©.</p>
<p>Nous prÃ©sentons ici que les meilleurs rÃ©sultats obtenus par SVM car le but de ce travail nâ€™est pas dâ€™Ã©tudier les diffÃ©rences dâ€™algorithmes, dâ€™autant plus quâ€™il existe aujourdâ€™hui un champ dâ€™Ã©tudes appelÃ© automated machine learning qui permet de chercher automatiquement le meilleur algorithme avec les meilleurs paramÃ¨tres pour une tÃ¢che donnÃ©e.</p>
<p>La Table 3 rÃ©capitule les rÃ©sultats :</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p><br/>ModÃ¨les</p></th>
<th class="head"><p><br/>Dimension</p></th>
<th class="head"><p><br/>Performance (accuracy)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><br/>Model_1000_100dim<br/> <br/></p></td>
<td><p><br/>500</p></td>
<td><p><br/>0.74</p></td>
</tr>
<tr class="row-odd"><td><p><br/>Model_8000_100dim<br/> <br/></p></td>
<td><p><br/>500</p></td>
<td><p><br/>0.82<br/> <br/></p></td>
</tr>
<tr class="row-even"><td><p><br/>ModÃ¨le frWac<br/> <br/>model_frWac_skip<br/> <br/></p></td>
<td><p><br/>500</p></td>
<td><p><br/>0.81<br/> <br/>0.80<br/> <br/></p></td>
</tr>
</tbody>
</table></div>
<p>Table 3 : Performance des classifieurs multi-classes en fonction du modÃ¨le vectoriel</p>
<p>Lâ€™importance du corpus pour lâ€™entraÃ®nement des vecteurs mÃ©rite dâ€™Ãªtre soulignÃ©e. En augmentant le nombre dâ€™articles de 3000 Ã  24000, lâ€™accuracy est passÃ© de 0.74 Ã  0.82, dÃ©passant le score du modÃ¨le FrWac entraÃ®nÃ© sur 1.6 milliards de mots. Cela montre quâ€™un corpus spÃ©cifique est important et ce corpus peut sâ€™avÃ©rer plus pertinent quâ€™un corpus de grande taille pour la tÃ¢che de classification de textes.</p>
<p>Cependant, les F1 scores des classes politique et sociÃ©tÃ© restent bas. Ils sont respectivement 0.75 et 0.76, ce qui fait que lâ€™accuracy gÃ©nÃ©ral du classifieur SVM est infÃ©rieur au benchmark TF-IDF (0.82 vs 0.85).</p>
</section>
<section id="elaboration-des-features-dites-expertes">
<h3>Elaboration des features dites expertes<a class="headerlink" href="#elaboration-des-features-dites-expertes" title="Permalink to this heading">Â¶</a></h3>
<p>Pour amÃ©liorer davantage notre classifieur SVM, nous avons calculÃ© 5 features supplÃ©mentaires : diversitÃ© lexicale, distance cosinus entre un article et 4 termes les plus frÃ©quents Ã  chaque classe et enfin, un vecteur one-hot Ã  12 dimensions construit sur lâ€™absence et la prÃ©sence des 4 termes mentionnÃ©s plus haut. La diversitÃ© lexicale a Ã©tÃ© calculÃ©e en divisant le nombre de tokens uniques par le nombre de tokens total.</p>
<p>Pour Ã©valuer lâ€™effet de chaque feature, nous avons tout dâ€™abord exclu le vecteur du document et utilisÃ© la rÃ©gression logistique (mÃ©thode Newton-conjugate gradient) en gardant uniquement les features expertes. Les valeurs P&gt;|z| nous indiquent que la diversitÃ© lexicale est peu probable de contribuer Ã  la classification (0.986). En revanche, les distances cosinus et le vecteur one-hot sont tous pertinents (toutes les valeurs sont infÃ©rieures Ã  0.05).</p>
<p>Nous avons donc intÃ©grÃ© ces deux features dans le classifieur SVM. Lâ€™accuracy gÃ©nÃ©ral est montÃ© Ã  0.85 et les F1 scores montÃ©s Ã  0.80 pour les classes politique et sociÃ©tÃ©.</p>
</section>
</section>
<section id="conclusions-et-perspectives">
<h2>Conclusions et perspectives<a class="headerlink" href="#conclusions-et-perspectives" title="Permalink to this heading">Â¶</a></h2>
<p>Nous avons donc construit un corpus de 5 thÃ¨mes, appliquÃ© un prÃ©traitement typique sur les textes de chaque article, extrait et Ã©laborÃ© des features et enfin testÃ© les features sur divers classifieurs.</p>
<p>Quelques points mÃ©ritent dâ€™Ãªtre mentionnÃ©s :</p>
<ol class="simple">
<li><p>Lâ€™efficacitÃ© du plongement lexical est relativement indÃ©pendante du nombre de dimensions dans la tÃ¢che de classification de textes. En revanche, la taille du corpus est importante ainsi que la nature du corpus. Les vecteurs entraÃ®nÃ©s sur le corpus de 24000 articles ont atteint quasiment la mÃªme performance que les vecteurs entraÃ®nÃ©s sur le corpus FrWac.</p></li>
<li><p>Les features expertes sont utiles pour augmenter la performance de classification. Cela met en Ã©vidence lâ€™importance des connaissances spÃ©cifiques au domaine (Domain-Specific Knowledge).</p></li>
<li><p>Lime permet dâ€™expliquer les mÃ©thodes de machine learning et dâ€™amÃ©liorer la performance des mÃ©thodes. Dans la section 4.1, nous avons montrÃ© que la suppression des mots non pertinents Ã  la classification permet dâ€™augmenter lâ€™accuracy de 0.82 Ã  0.85.</p></li>
</ol>
</section>
<section id="tutoriels-a-venir">
<h2>Tutoriels Ã  venir<a class="headerlink" href="#tutoriels-a-venir" title="Permalink to this heading">Â¶</a></h2>
<p>Dans le domaine de la classification de textes, les rÃ©seaux de neurones du type RNN ont fait preuve dâ€™efficacitÃ©. Des modÃ¨les de langues prÃ©-entraÃ®nÃ©s du type Bert (Vaswani et al., 2017) ont davantage poussÃ© les limites de performance. Des features linguistiques basÃ©s sur les propriÃ©tÃ©s morpho-syntaxiques des tokens peuvent aussi sâ€™avÃ©rer utiles.</p>
<p>A trÃ¨s bientÃ´t pour plus de tutoriels :D</p>
</section>
<section id="references">
<h2>RÃ©fÃ©rences<a class="headerlink" href="#references" title="Permalink to this heading">Â¶</a></h2>
<p>Fauconnier, J.-P. (2015). French word embeddings.</p>
<p>Firth, J. R. (1957). A synopsis of linguistic theory, 1930-1955. Studies in Linguistic Analysis.</p>
<p>Harris, Z. S. (1954). Distributional structure. Word, 10(2â€“3), 146â€“162.</p>
<p>Mikolov, T., Chen, K., Corrado, G., &amp; Dean, J. (2013). Efficient estimation of word representations in vector space. ArXiv Preprint ArXiv:1301.3781
.
Qi, P., Zhang, Y., Zhang, Y., Bolton, J., &amp; Manning, C. D. (2020). Stanza: A Python natural language processing toolkit for many human languages. ArXiv Preprint ArXiv:2003.07082
.
Ribeiro, M. T., Singh, S., &amp; Guestrin, C. (2016). â€œWhy Should I Trust You?â€: Explaining the Predictions of Any Classifier. ArXiv:1602.04938 [Cs, Stat]. http://arxiv.org/abs/1602.04938</p>
<p>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., &amp; Polosukhin, I. (2017). Attention is all you need. ArXiv Preprint ArXiv:1706.03762.</p>
</section>
</section>

      </article>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../transformers/index.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Transformers in NLP with PyTorch, TensorFlow and Hugging Face</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="02_classification_prenoms_fr.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Classification de prÃ©noms en genre (masculin/fÃ©minin) ğŸ‡«ğŸ‡·</div>
                
              </div>
            </a>
        </div>

        <div class="related-information">
              Copyright &#169; 2022, Xiaoou Wang
            |
            Built with <a href="https://www.sphinx-doc.org/">Sphinx</a>
              and
              <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
              <a href="https://github.com/pradyunsg/furo">Furo theme</a>.
            |
            <a class="muted-link" href="../sources/nlp/03_classification_lemonde_fr.md.txt"
               rel="nofollow">
              Show Source
            </a>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Text Classification: du TF-IDF aux word embeddings en passant par features expertes ğŸ‡«ğŸ‡·</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#structure-du-tutoriel">Structure du tutoriel</a></li>
<li><a class="reference internal" href="#pretraitement-du-corpus">PrÃ©traitement du corpus</a></li>
<li><a class="reference internal" href="#classification-de-textes">Classification de textes</a><ul>
<li><a class="reference internal" href="#etablissement-dune-baseline">Ã‰tablissement dâ€™une baseline</a></li>
<li><a class="reference internal" href="#classification-a-base-du-plongement-lexical">Classification Ã  base du plongement lexical</a></li>
<li><a class="reference internal" href="#elaboration-des-features-dites-expertes">Elaboration des features dites expertes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conclusions-et-perspectives">Conclusions et perspectives</a></li>
<li><a class="reference internal" href="#tutoriels-a-venir">Tutoriels Ã  venir</a></li>
<li><a class="reference internal" href="#references">RÃ©fÃ©rences</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </main>
</div>
    <script id="documentation_options" data-url_root="../" src="../static/documentation_options.js"></script>
    <script data-url_root="../" id="documentation_options" src="../static/documentation_options.js"></script>
    <script src="../static/doctools.js"></script>
    <script src="../static/sphinx_highlight.js"></script>
    <script src="../static/clipboard.min.js"></script>
    <script src="../static/copybutton.js"></script>
    <script src="../static/tabs.js"></script>
    <script>
</script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" />
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-58WGY2PHYB"></script>
<script src='https://kit.fontawesome.com/a076d05399.js' crossorigin='anonymous'></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-58WGY2PHYB');
</script>
<!-- Default Statcounter code for nlpinfrench
http://nlpinfrench.fr -->
<script type="text/javascript">
var sc_project=12500373;
var sc_invisible=1;
var sc_security="def60251";
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics
Made Easy - StatCounter" href="https://statcounter.com/"
target="_blank"><img class="statcounter"
src="https://c.statcounter.com/12500373/0/def60251/1/"
alt="Web Analytics Made Easy -
StatCounter"></a></div></noscript>
<!-- End of Statcounter Code -->
<script src="https://cdn.jsdelivr.net/gh/cferdinandi/gumshoe@4.0/dist/gumshoe.polyfills.min.js"></script>
</script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../static/custom.js"></script>
    <script src="../static/scripts/main.js?digest=e931d09b2a40c1bb82b542effe772014573baf67"></script></body>
</html>
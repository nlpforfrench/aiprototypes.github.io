# Text Classification: du TF-IDF aux word embeddings en passant par features expertes üá´üá∑

[Xiaoou WANG](https://https://scholar.google.fr/citations?user=vKAMMpwAAAAJ&hl=en), [Xingyu LIU](https://www.linkedin.com/in/xingyu-liu-aba896a1/)

## Introduction

La classification de textes est une t√¢che courante en traitement automatique des langues (TAL). Dans ce tutoriel nous allons explorer diverses features (TF-IDF, plongement lexical, features linguistiques) alimentant √† leur tour des mod√®les vari√©s dont entre autres la r√©gression logistique, classification na√Øve bay√©sienne et perceptron multicouche.

Le but de ce tutoriel est de construire un classifieur qui permet de cat√©goriser correctement des textes en 3 classes : soci√©t√©, √©conomie et politique.

```{admonition} Teaser
Exclusivit√©s :D
```

1)	Le corpus a √©t√© construit gr√¢ce au site des archives de ¬´ le monde ¬ª. Regardez [ici](../web/01_lemonde) pour un tutoriel rapide.

2)	Une mise en parall√®le a √©t√© soigneusement construite pour montrer l‚Äôefficacit√© des vecteurs lexicaux entra√Æn√©s sur un corpus sp√©cifique qui atteint la m√™me performance d‚Äôun mod√®le √† partir du corpus frWac de 1.6 milliards de mots  (Fauconnier, 2015).

3)	Le package Lime (Ribeiro et al., 2016) a √©t√© utilis√© pour comprendre et par la suite am√©liorer les features.

4)	Quelques features linguistiques dites expertes ont √©t√© construites pour am√©liorer la performance de classification suite √† une s√©lection manuelle s‚Äôappuyant sur la r√©gression logistique.

5)	Ce tutoriel est un issu d'un travail d'√©quipe, nous avons veill√© au bon d√©roulement et √† la bonne r√©partition des t√¢ches en mettant en place toute une panoplie d‚Äôoutils en logistique comme `la m√©thode agile`, [Github](https://github.com/xiaoouwang/tuto_classification), `Omniplan` (outil de gestion de projet) et un document [Google Docs](https://docs.google.com/document/d/11vaB74HV0GxerkVm9Pv_mgnhXN27QVegFYPdPA34t5g/edit?usp=sharing) auquel vous pouvez vous r√©f√©rer pour revoir comment ce tutoriel d'√©quipe a √©t√© r√©alis√© pendant plus d'un mois.

La r√©partition des t√¢ches est illustr√©e succinctement par la Figure 1 :

![](02_classification_lemonde_images/ac2e3489.png)

Figure 1 : R√©partition des t√¢ches pendant l'√©criture de ce tutoriel

## Structure du tutoriel

1. Nous pr√©sentons le pr√©traitement de notre corpus.

2. Ensuite nous utilisons TF-IDF comme feature et un classifieur bay√©sien pour √©tablir une baseline. Le package `Lime` est utilis√© pour comprendre le fonctionnement du classifieur qui a ensuite permis une l√©g√®re am√©lioration de performance.

3. La baseline √©tablie, divers mod√®les vectoriels sont entra√Æn√©s sur des corpus de diff√©rentes tailles en utilisant diff√©rents param√®tres. Cela nous a permis d'√©tudier les effets des param√®tres et de la taille du corpus d'entra√Ænement.

4. Enfin pour davantage augmenter la pr√©cision de classification nous introduisons quelques features linguistiques expertes, ces derni√®res √©tant soumises √† un test bas√© sur la r√©gression logistique pour que les features les plus pertinentes puissent √™tre mises en avant.

## Pr√©traitement du corpus

Nous avons scrap√© 9000 articles par th√®me. Les th√®mes principaux sont : soci√©t√©, sport, √©conomie, culture et politique. Nous avons ensuite s√©lectionn√© al√©atoirement 1000 articles pour la t√¢che de classification.

La tokenisation a √©t√© effectu√©e avec le package Stanza (Qi et al., 2020). Ce tokeniseur a notamment l‚Äôavantage de regrouper par d√©faut des mots s√©par√©s par tiret du type ¬´ gratte-ciel ¬ª, alors que dans Spacy un tel comportement n√©cessite une configuration ad hoc engendrant d‚Äôautres probl√®mes.

Nous avons aussi essay√© de regrouper les entit√©s nomm√©es dans un seul token car cela permet de garder des informations s√©mantiques intactes. Dans Spacy il est facile d‚Äôy proc√©der ainsi mais dans Stanza il n‚Äôexiste pas de fonction pr√©-d√©finie. Nous avons donc soumis un [issue](https://github.com/stanfordnlp/stanza/issues/583) sur Github et propos√© notre propre solution sur le m√™me lien au cas o√π cela pourrait servir la communaut√©.

Ensuite nous avons lemmatis√© les tokens et enlev√© les mots vides et ponctuation. Pour la liste des mots vides nous avons combin√© les ensembles propos√©s par `NLTK` et `Spacy`. Notons que cette √©tape, en enlevant les tokens peu pertinents √† chaque document, constitue en essence une tentative de r√©duction de dimensionnalit√©.

Enfin nous avons mis tous les tokens en minuscules. L‚Äôensemble des op√©rations est illustr√© par la Figure 2 :

![](02_classification_lemonde_images/768a8e62.png)

Figure 2 : Pr√©traitement en amont des articles en vue de la classification

Notons que nous avons aussi pr√©par√© une version enrichie du corpus en xml pour calculer des features expertes. Il y a en tout 6 colonnes signifiant id, token, lemme, partie du discours, t√™te et relation de d√©pendance. Par contraintes d‚Äôespace nous ne d√©taillons pas la proc√©dure de pr√©paration. Chaque article est ench√¢ss√© dans le tag `<art>` avec label comme attribut et classe comme valeur. Ensuite chaque phrase est contenue dans un tag `<s>`. La Figure 3 montre la structure du fichier xml :

![](02_classification_lemonde_images/c6849494.png)

Figure 3 : Structure du corpus enrichi en xml

## Classification de textes

### √âtablissement d‚Äôune baseline

Vu que notre classifieur recourra principalement au plongement lexical, il nous a paru utile d‚Äô√©tablir une baseline en utilisant un vecteur TF-IDF.

Un document peut √™tre repr√©sent√© de diverses fa√ßons selon le traitement des mots contenus dans le document. Le mod√®le le plus simple est le sac de mots qui compte l'occurrence de chaque token afin de g√©n√©rer une matrice documents-termes (MDT). Ce mod√®le est quelque peu simpliste car l'occurrence des tokens augmente en fonction de la longueur du document. Pour rem√©dier √† ce d√©faut la MDT peut √™tre modifi√©e pour repr√©senter non plus la fr√©quence absolue mais la fr√©quence relative des tokens. Cependant il subsiste toujours le probl√®me des mots vides car ces derniers sont quasiment toujours les plus fr√©quents (cf. la loi de Zipf √† ce propos).

Pour faire face √† ce probl√®me une autre mesure est propos√©e : celle de TF-IDF, la formule de cette mesure est la suivante :

```{figure} 02_classification_lemonde_images/a322e8b3.png
:align: center
Figure 4 : Formule de TF-IDF
```

L'efficacit√© de cette mesure est bas√©e sur l‚Äôhypoth√®se selon laquelle un terme doit √™tre √† la fois fr√©quent et sp√©cifique √† un document pour caract√©riser ce dernier. Notons que cette feature est peu gourmande en termes de calcul.

Nous avons utilis√© scikit-learn pour impl√©menter la classification. La feature est repr√©sent√©e par le vecteur TF-IDF et le classifieur utilis√© est le classifieur bay√©sien. Nous avons utilis√© un split de 0.3, ce qui fait qu‚Äôenviron 300 articles par th√®me ont √©t√© utilis√©s comme test. Le random state a √©t√© configur√© √† 42 pour garantir la reproductibilit√© de notre travail.

Dans un premier temps nous avons essay√© de classifier tous les 5 th√®mes pour en s√©lectionner ceux qui pr√©sentent le plus de difficult√©s. La Figure 5 montre la performance du classifieur sur les articles de 5 th√®mes :

![](02_classification_lemonde_images/e6e2fd44.png)

Figure 5 : Matrice de confusion du classifieur bay√©sien sur les articles de 5 th√®mes

Le fait que les classes `√©conomie, politique et soci√©t√©` sont les plus faciles √† confondre pour le classifieur nous a d√©cid√©s √† choisir ces 3 th√®mes pour notre projet. La Figure 6 rapporte les m√©triques principales √† l‚Äôissue de cette s√©lection :

![](02_classification_lemonde_images/12d5a6a6.png)

Figure 6 : M√©triques classiques pour la classification de textes sur les articles en 3 th√®mes

Vous pouvez voir que la classe √©conomie est la mieux class√©e et les deux autres pr√©sentent une plus grande confusion, ce qui est plut√¥t attendu car la classe √©conomie renvoie √† une notion plus restreinte.

Avec le package Lime nous avons pu voir comment est proc√©d√© le classifieur pour classer les articles, la Figure 7 montre l‚Äôexemple d‚Äôun seul article. L‚Äôinterpr√©tation de cette figure est plut√¥t intuitive : La l√©gende d‚Äôen haut √† gauche pr√©sente les probabilit√©s respectives que cet article appartient aux 3 classes (la somme = 1). Lorsque le score se situe √† droite, il contribue positivement √† la classification.

![](02_classification_lemonde_images/e1cb0478.png)

Figure 7 : Contribution des termes √† la classification d‚Äôun article

Les fonctionnalit√©s propos√©es par Lime nous ont incit√©s √† faire un post-traitement susceptible d‚Äôaugmenter la performance du classifieur. Nous avons extrait les 3 premiers termes de chaque pr√©diction de classe au cas o√π la pr√©diction serait mauvaise. Cette liste de termes constitue par la suite une liste de ¬´ mots inad√©quats ¬ª avec laquelle nous filtrons le texte de chaque article. Nous avons ensuite r√©-entra√Æn√© le classifieur, portant l‚Äôaccuracy global de 0.82 √† 0.85. Ce score de 0.85 a √©t√© retenu par la suite comme benchmark pour notre t√¢che de classification.

### Classification √† base du plongement lexical

Dans cette sous-section nous allons utiliser le plongement lexical pour caract√©riser un mot et par la suite un article en prenant la moyenne de tous les vecteurs lexicaux constituant l‚Äôarticle.

Le plongement lexical vise √† repr√©senter un mot par un vecteur de nombres r√©els. Autrement dit, le principe fondamental consiste √† repr√©senter un concept linguistique par l'interm√©diaire d'une repr√©sentation math√©matique. Le mot ¬´ chien ¬ª serait repr√©sent√© par exemple par un vecteur √† 3 dimensions [1.3, 2.2, 4,1].

Au cours de la recherche d'une repr√©sentation math√©matique ad√©quate, certaines id√©es ont permis d'√©clairer le chemin dont entre autres l'hypoth√®se distributionnelle de Harris (distributional hypothesis, (Harris, 1954)) dans le domaine de la s√©mantique distributionnelle. On retiendra aussi la fameuse phrase de Firth : Vous conna√Ætrez un mot par ses voisinages (You shall know a word by the company it keeps (Firth, 1957)). L‚Äôimpl√©mentation informatique la plus courante de cette id√©e est bas√©e sur l‚Äôarticle de (Mikolov et al., 2013). Notons que le plongement lexical est en essence le produit d‚Äôune t√¢che reposant elle-m√™me sur l‚Äôentra√Ænement d‚Äôun r√©seau de neurones . Deux t√¢ches sont possibles pour obtenir les vecteurs : soit on essaie de pr√©dire un mot √† partir de son contexte (CBOW), soit on pr√©dit l‚Äôentourage d‚Äôun mot (Skip-gram).

Pour entra√Æner le mod√®le vectoriel nous avons utilis√© diff√©rents corpus et diff√©rents param√®tres. La Table 1 r√©capitule les informations pertinentes (Les deux mod√®les FrWac ont √©t√© t√©l√©charg√©s sur https://fauconnier.github.io/) :

|    <br>Nom de mod√®le                                                                                             |    <br>M√©thode      |    <br>Dimension           |    <br>Corpus                        |
|------------------------------------------------------------------------------------------------------------------|---------------------|----------------------------|--------------------------------------|
|    <br>model_frWac_skip                                                                                          |    <br>Skip-gram    |    <br>500                 |    <br>FrWac                         |
|    <br>model_frWac                                                                                               |    <br>CBOW         |    <br>500                 |    <br>FrWac                         |
|    <br>Model_1000_100dim<br>   <br>Model_1000_200dim<br>   <br>Model_1000_500dim<br>   <br>Model_1000_1000dim    |    <br>CBOW         |    <br>100/200/500/1000    |    <br>3000 articles en 3 th√®mes     |
|    <br>Model_8000_100dim<br>   <br>Model_8000_200dim<br>   <br>Model_8000_500dim<br>   <br>Model_8000_1000dim    |    <br>CBOW         |    <br>100/200/500/1000    |    <br>24000 articles en 3 th√®mes    |

Table 1 : Mod√®les vectoriels utilis√©s pour la classification de textes

Pour √©valuer l‚Äôeffet de mod√®le sur la performance de classification, nous avons commenc√© par utiliser la r√©gression logistique qui aboutit √† une d√©cision binaire. Les r√©sultats sont pr√©sent√©s dans la Table 2 :

|    <br>Mod√®les                                                                                                   |    <br>Classes                  |    <br>Performance (accuracy)                               |
|------------------------------------------------------------------------------------------------------------------|---------------------------------|-------------------------------------------------------------|
|    <br>Model_1000_100dim<br>   <br>Model_1000_200dim<br>   <br>Model_1000_500dim<br>   <br>model_1000_1000dim    |    <br>√âconomie vs politique    |    <br>0.87<br>   <br>0.86<br>   <br>0.86<br>   <br>0.86    |
|    <br>Model_8000_100dim<br>   <br>Model_8000_200dim<br>   <br>Model_8000_500dim<br>   <br>model_8000_1000dim    |    <br>√âconomie vs politique    |    <br>0.92<br>   <br>0.92<br>   <br>0.90<br>   <br>0.92    |
|    <br>Model_1000_100dim<br>   <br>Model_1000_200dim<br>   <br>Model_1000_500dim<br>   <br>model_1000_1000dim    |    <br>√âconomie vs soci√©t√©      |    <br>0.82<br>   <br>0.81<br>   <br>0.81<br>   <br>0.79    |
|    <br>Model_8000_100dim<br>   <br>Model_8000_200dim<br>   <br>Model_8000_500dim<br>   <br>model_8000_1000dim    |    <br>√âconomie vs soci√©t√©      |    <br>0.91<br>   <br>0.92<br>   <br>0.92<br>   <br>0.91    |
|    <br>Model_1000_100dim<br>   <br>Model_1000_200dim<br>   <br>Model_1000_500dim<br>   <br>model_1000_1000dim    |    <br>Politique vs soci√©t√©     |    <br>0.82<br>   <br>0.78<br>   <br>0.83<br>   <br>0.79    |
|    <br>Model_8000_100dim<br>   <br>Model_8000_200dim<br>   <br>Model_8000_500dim<br>   <br>model_8000_1000dim    |    <br>Politique vs soci√©t√©     |    <br>0.84<br>   <br>0.84<br>   <br>0.81<br>   <br>0.84    |

Table 2 : Performance des classifieurs binaires en fonction du mod√®le vectoriel

Cette table nous permet de faire deux remarques :

1) l‚Äôaugmentation de la dimensionnalit√© ne s‚Äôaccompagne pas d‚Äôune augmentation de performance.

2) l‚Äôaugmentation du nombre d‚Äôarticles augmente la performance des vecteurs dans la t√¢che de classification. Cependant nous pouvons voir que l‚Äôaccuracy des classes politique et soci√©t√© reste bas et le changement de mod√®le aussi bien sur le plan dimensionnel que sur le plan du nombre d‚Äôarticles, apporte un gain de performance plus faible par rapport √† d‚Äôautres combinaisons de classes.

Nous utilisons ensuite divers classifieurs multi-classes (onevsRest, kNeighbors, SVM, Bay√©sien, Perceptron multicouche, etc.) pour mener la m√™me comparaison de mod√®les, sans inclure l‚Äôeffet de dimensionnalit√©.

Nous pr√©sentons ici que les meilleurs r√©sultats obtenus par SVM car le but de ce travail n‚Äôest pas d‚Äô√©tudier les diff√©rences d‚Äôalgorithmes, d‚Äôautant plus qu‚Äôil existe aujourd'hui un champ d‚Äô√©tudes appel√© automated machine learning qui permet de chercher automatiquement le meilleur algorithme avec les meilleurs param√®tres pour une t√¢che donn√©e.

La Table 3 r√©capitule les r√©sultats :

|    <br>Mod√®les                                                |    <br>Dimension    |    <br>Performance (accuracy)             |
|---------------------------------------------------------------|---------------------|-------------------------------------------|
|    <br>Model_1000_100dim<br>   <br>                           |    <br>500          |    <br>0.74                               |
|    <br>Model_8000_100dim<br>   <br>                           |    <br>500          |    <br>0.82<br>   <br>                    |
|    <br>Mod√®le frWac<br>   <br>model_frWac_skip<br>   <br>     |    <br>500          |    <br>0.81<br>   <br>0.80<br>   <br>     |

Table 3 : Performance des classifieurs multi-classes en fonction du mod√®le vectoriel

L‚Äôimportance du corpus pour l‚Äôentra√Ænement des vecteurs m√©rite d‚Äô√™tre soulign√©e. En augmentant le nombre d‚Äôarticles de 3000 √† 24000, l‚Äôaccuracy est pass√© de 0.74 √† 0.82, d√©passant le score du mod√®le FrWac entra√Æn√© sur 1.6 milliards de mots. Cela montre qu‚Äôun corpus sp√©cifique est important et ce corpus peut s‚Äôav√©rer plus pertinent qu‚Äôun corpus de grande taille pour la t√¢che de classification de textes.

Cependant, les F1 scores des classes politique et soci√©t√© restent bas. Ils sont respectivement 0.75 et 0.76, ce qui fait que l‚Äôaccuracy g√©n√©ral du classifieur SVM est inf√©rieur au benchmark TF-IDF (0.82 vs 0.85).

### Elaboration des features dites expertes

Pour am√©liorer davantage notre classifieur SVM, nous avons calcul√© 5 features suppl√©mentaires : diversit√© lexicale, distance cosinus entre un article et 4 termes les plus fr√©quents √† chaque classe et enfin, un vecteur one-hot √† 12 dimensions construit sur l‚Äôabsence et la pr√©sence des 4 termes mentionn√©s plus haut. La diversit√© lexicale a √©t√© calcul√©e en divisant le nombre de tokens uniques par le nombre de tokens total.

Pour √©valuer l‚Äôeffet de chaque feature, nous avons tout d‚Äôabord exclu le vecteur du document et utilis√© la r√©gression logistique (m√©thode Newton-conjugate gradient) en gardant uniquement les features expertes. Les valeurs P>|z| nous indiquent que la diversit√© lexicale est peu probable de contribuer √† la classification (0.986). En revanche, les distances cosinus et le vecteur one-hot sont tous pertinents (toutes les valeurs sont inf√©rieures √† 0.05).

Nous avons donc int√©gr√© ces deux features dans le classifieur SVM. L‚Äôaccuracy g√©n√©ral est mont√© √† 0.85 et les F1 scores mont√©s √† 0.80 pour les classes politique et soci√©t√©.

## Conclusions et perspectives

Nous avons donc construit un corpus de 5 th√®mes, appliqu√© un pr√©traitement typique sur les textes de chaque article, extrait et √©labor√© des features et enfin test√© les features sur divers classifieurs.

Quelques points m√©ritent d‚Äô√™tre mentionn√©s :

1) L'efficacit√© du plongement lexical est relativement ind√©pendante du nombre de dimensions dans la t√¢che de classification de textes. En revanche, la taille du corpus est importante ainsi que la nature du corpus. Les vecteurs entra√Æn√©s sur le corpus de 24000 articles ont atteint quasiment la m√™me performance que les vecteurs entra√Æn√©s sur le corpus FrWac.

2) Les features expertes sont utiles pour augmenter la performance de classification. Cela met en √©vidence l‚Äôimportance des connaissances sp√©cifiques au domaine (Domain-Specific Knowledge).

3) Lime permet d‚Äôexpliquer les m√©thodes de machine learning et d‚Äôam√©liorer la performance des m√©thodes. Dans la section 4.1, nous avons montr√© que la suppression des mots non pertinents √† la classification permet d‚Äôaugmenter l‚Äôaccuracy de 0.82 √† 0.85.

## Tutoriels √† venir

Dans le domaine de la classification de textes, les r√©seaux de neurones du type RNN ont fait preuve d‚Äôefficacit√©. Des mod√®les de langues pr√©-entra√Æn√©s du type Bert (Vaswani et al., 2017) ont davantage pouss√© les limites de performance. Des features linguistiques bas√©s sur les propri√©t√©s morpho-syntaxiques des tokens peuvent aussi s'av√©rer utiles.

A tr√®s bient√¥t pour plus de tutoriels :D

## R√©f√©rences

Fauconnier, J.-P. (2015). French word embeddings.

Firth, J. R. (1957). A synopsis of linguistic theory, 1930-1955. Studies in Linguistic Analysis.

Harris, Z. S. (1954). Distributional structure. Word, 10(2‚Äì3), 146‚Äì162.

Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space. ArXiv Preprint ArXiv:1301.3781
.
Qi, P., Zhang, Y., Zhang, Y., Bolton, J., & Manning, C. D. (2020). Stanza: A Python natural language processing toolkit for many human languages. ArXiv Preprint ArXiv:2003.07082
.
Ribeiro, M. T., Singh, S., & Guestrin, C. (2016). ‚ÄúWhy Should I Trust You?‚Äù: Explaining the Predictions of Any Classifier. ArXiv:1602.04938 [Cs, Stat]. http://arxiv.org/abs/1602.04938

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin, I. (2017). Attention is all you need. ArXiv Preprint ArXiv:1706.03762.


<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Classification de prÃ©noms en genre (masculin/fÃ©minin) ğŸ‡«ğŸ‡·" href="02_classification_prenoms_fr.html" /><link rel="prev" title="NLP and Machine Learning-related" href="index.html" />

    <meta name="generator" content="sphinx-7.2.6, furo 2021.02.28.beta28"/>
        <title>Comparer Spacy, StanfordNLP et TreeTagger sur un corpus oral et un corpus de presse ğŸ‡«ğŸ‡· - </title>
      <link rel="stylesheet" href="../static/styles/furo.css?digest=be5985a4059b5c2cd56ed0804790452beca62674">
    <link rel="stylesheet" href="../static/pygments.css">
    <link media="(prefers-color-scheme: dark)" rel="stylesheet" href="../static/pygments_dark.css">
    


<style>
  :root {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media (prefers-color-scheme: dark) {
    :root {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
  }

  /* For allowing end-user-specific overrides */
  .override-light {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  .override-dark {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
  }
</style><link rel="stylesheet" type="text/css" href="../static/pygments.css?v=80d5e7a1" />
    <link rel="stylesheet" type="text/css" href="../static/styles/furo.css?v=5f0bca00" />
    <link rel="stylesheet" type="text/css" href="../static/copybutton.css?v=f78ba3b0" />
    <link rel="stylesheet" type="text/css" href="../static/tabs.css?v=eb6ac661" />
    <link rel="stylesheet" type="text/css" href="../static/gallery.css?v=f1f6b6fd" />
    <link rel="stylesheet" type="text/css" href="../static/custom.css?v=d268d653" />
    <link rel="stylesheet" href="../static/styles/furo-extensions.css?digest=d391b54134226e4196576da3bdb6dddb7e05ba2b"></head>
  <body dir="">
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke-width="1.5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z"/>
      <line x1="4" y1="6" x2="20" y2="6" />
      <line x1="10" y1="12" x2="20" y2="12" />
      <line x1="6" y1="18" x2="20" y2="18" />
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand"></div></a>
    </div>
    <div class="header-right">
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text"></span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html">
  <input class="sidebar-search" placeholder=Search name="q">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">NLP and Machine Learning-related</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label for="toctree-checkbox-1"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Comparer Spacy, StanfordNLP et TreeTagger sur un corpus oral et un corpus de presse ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_classification_prenoms_fr.html">Classification de prÃ©noms en genre (masculin/fÃ©minin) ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_classification_lemonde_fr.html">Text Classification: du TF-IDF aux word embeddings en passant par features expertes ğŸ‡«ğŸ‡·</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../transformers/index.html">Transformers in NLP with PyTorch, TensorFlow and Hugging Face</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label for="toctree-checkbox-2"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../transformers/01_theorie_en.html">10 questions on Bert ğŸ‡¬ğŸ‡§</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transformers/01_theorie_fr.html">10 questions sur Bert ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transformers/02_firstBert_fr.html">Classification de commentaires avec Camembert sans prise de tÃªte : les fondamentaux ğŸ‡«ğŸ‡·</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../better_programmer/index.html">Better Programmer</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label for="toctree-checkbox-3"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/01_python_fr.html">Mieux programmer en Python ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/02_git3_en.html">A serious guide to git ğŸ‡¬ğŸ‡§</a></li>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/03_jupyter_remote_pycharm.html">Connect to remote jupyter notebook in Pycharm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/04_oop_web_scraping_en.html">Understand objected-oriented programming (OOP) by building a minimal Web Scraping framework ğŸ‡¬ğŸ‡§</a></li>
<li class="toctree-l2"><a class="reference internal" href="../better_programmer/05_oop_web_scraping_cooper_en.html">Be a responsible programmer when doing Object-Oriented Programming ğŸ‡¬ğŸ‡§</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../algo/index.html">Algorithms and data structures by examples in Python</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label for="toctree-checkbox-4"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../algo/01_intro_en.html">Algorithm or many ways of solving a problem ğŸ‡¬ğŸ‡§</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/01_intro_fr.html">Algorithme ou plusieurs faÃ§ons de rÃ©soudre un problÃ¨me ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/02_ds_en.html">Data structures or many ways of organizing your stuff ğŸ‡¬ğŸ‡§</a></li>
<li class="toctree-l2"><a class="reference internal" href="../algo/099algo_map.html">Roadmap and cheatsheet of algorithms and data structures</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../web/index.html">Web Related</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label for="toctree-checkbox-5"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../web/01_lemonde_en.html">Complete tutorial on scraping French news from Le Monde ğŸ‡¬ğŸ‡§</a></li>
<li class="toctree-l2"><a class="reference internal" href="../web/01_lemonde_fr.html">Scraper Â« le monde Â» et construire ton propre corpus ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../web/02_forum_en.html">On your way to scraping French forums ğŸ‡¬ğŸ‡§</a></li>
<li class="toctree-l2"><a class="reference internal" href="../web/03_django_en.html">Deploying Django app on Ubuntu at digitalocean + SSL certificate ğŸ‡¬ğŸ‡§</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../linguistique_informatique/index.html">Computational Linguistics in R</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label for="toctree-checkbox-6"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../linguistique_informatique/01_zipf_fr.html">La loi de Zipf illustrÃ©e avec gutenbergr en R ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linguistique_informatique/02_mca_ergatif_fr.html">Analyse des Correspondances Multiples : le cas de lâ€™ergatif en warlipiri ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linguistique_informatique/03_pca_inclusion_fr.html">Analyse en composantes principales (PCA) : prÃ©positions dâ€™inclusion en franÃ§ais ğŸ‡«ğŸ‡·</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../high_performance_python/index.html">High performance computing</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label for="toctree-checkbox-7"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../high_performance_python/01_parallel_primer_en.html">Parallelization in Python: a beginnerâ€™s guide (1, using map)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../codebase/index.html">My Codebase</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label for="toctree-checkbox-8"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../codebase/01_bash.html">My codebase for bash/shell script (macOS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../codebase/02_tmux.html">Tumux-related code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../codebase/03_python.html">My python codebase (including packages/libraries)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../codebase/05_pytorch.html">Pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../codebase/06_pandas.html">Pandas codebase</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../math/index.html">Mathematics in Machine Learning and NLP</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label for="toctree-checkbox-9"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../math/01_math_fr.html">Machine Learning : algorithmes et mathÃ©matiques ğŸ‡«ğŸ‡·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/01_math_fr.html">Machine Learning : algorithmes et mathÃ©matiques ğŸ‡«ğŸ‡·</a></li>
</ul>
</li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <main class="main">
    <div class="content">
      <article role="main">
        <label class="toc-overlay-icon toc-content-icon" for="__toc">
          <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
        </label>
        <section id="comparer-spacy-stanfordnlp-et-treetagger-sur-un-corpus-oral-et-un-corpus-de-presse">
<h1>Comparer Spacy, StanfordNLP et TreeTagger sur un corpus oral et un corpus de presse ğŸ‡«ğŸ‡·<a class="headerlink" href="#comparer-spacy-stanfordnlp-et-treetagger-sur-un-corpus-oral-et-un-corpus-de-presse" title="Link to this heading">Â¶</a></h1>
<p><a class="reference external" href="https://scholar.google.fr/citations?user=vKAMMpwAAAAJ&amp;hl=en">Xiaoou WANG</a>, <a class="reference external" href="https://www.linkedin.com/in/xingyu-liu-aba896a1/">Xingyu LIU</a></p>
<section id="motivation">
<h2>Motivation<a class="headerlink" href="#motivation" title="Link to this heading">Â¶</a></h2>
<p>Lâ€™annotation morphosyntaxique est une tÃ¢che consistant Ã  assigner des informations grammaticales Ã  chaque mot dâ€™un
texte. Un tagger (ou Ã©tiqueteur) est typiquement couplÃ© Ã  un outil de segmentation en phrases et en mots et/ou Ã  un
lemmatiseur.</p>
<p>Cette tÃ¢che est effectuÃ©e en amont des analyses textuelles plus poussÃ©es telles que lâ€™analyse sentimentale et lâ€™analyse
stylomÃ©trique et la qualitÃ© de ces derniÃ¨res dÃ©pend considÃ©rablement du choix dâ€™un bon Ã©tiqueteur morphosyntaxique.</p>
<p>Le but de ce rapport est dâ€™Ã©valuer la performance de 3 Ã©tiqueteurs morphosyntaxiques sur deux corpus issus du mÃªme
domaine (santÃ©) mais de registres linguistiques bien distincts : lâ€™un de nature journalistique et lâ€™autre dâ€™un niveau
plus familier.</p>
<p>Cette Ã©valuation Ã  deux facteurs (Ã©tiqueteur et corpus) est justifiÃ©e par les constats suivants :</p>
<ol class="simple">
<li><p>Des difficultÃ©s ont Ã©tÃ© rapportÃ©es pour lâ€™annotation des corpus de franÃ§ais non Ã©crit (dans le sens du fond mais pas
de la forme, un texte Ã©crit peut trÃ¨s bien retranscrire une conversation orale). Pour le franÃ§ais oral par exemple
des tÃ©moignages ont Ã©tÃ© nombreux (voir entre autres (Benzitoun et al., 2012; Eshkol-Taravella et al., 2011)) parce
que le langage oral possÃ¨de de nombreuses caractÃ©ristiques propres Ã  son genre (hÃ©sitations, rÃ©pÃ©titions, reprises,
incises, amorces de mot, etcâ€¦).</p></li>
<li><p>Quant Ã  la comparaison dâ€™Ã©tiqueteurs, il est souvent question de comparer les rÃ©sultats au niveau de la prÃ©cision (
mesures de prÃ©cision, rappel et F-mesure). Mais une vue plus globale sur les particularitÃ©s de diffÃ©rents
Ã©tiqueteurs : temps dâ€™exÃ©cution, mÃ©thodes dâ€™entraÃ®nement, possibilitÃ©s de customisation est plus utile pour apprÃ©cier
tant de facteurs contribuant Ã  la dÃ©cision finale dâ€™un tel ou tel Ã©tiqueteur.</p></li>
</ol>
</section>
<section id="etiqueteurs-parseurs-choisis">
<h2>Ã‰tiqueteurs/parseurs choisis<a class="headerlink" href="#etiqueteurs-parseurs-choisis" title="Link to this heading">Â¶</a></h2>
<p>Les 3 Ã©tiqueteurs sont Treetagger (Schmid, 1994), Spacy (Explosion, 2017) et StanfordNLP, rebaptisÃ© aujourdâ€™hui en
Stanza (Qi et al., 2020).</p>
</section>
<section id="constitution-du-corpus">
<h2>Constitution du corpus<a class="headerlink" href="#constitution-du-corpus" title="Link to this heading">Â¶</a></h2>
<p>Nous avons construit deux corpus en aspirant des textes de la rubrique santÃ©
de <code class="docutils literal notranslate"><span class="pre">le</span> <span class="pre">monde</span></code>(https://www.lemonde.fr/sante/) et <code class="docutils literal notranslate"><span class="pre">doctissimo</span></code>(https://forum.doctissimo.fr/sante/). La documentation de ce
processus se trouve <span class="xref myst">ici</span>.</p>
<p>100 articles journalistiques et 100 posts de forum ont Ã©tÃ© utilisÃ©s comme corpus de base.</p>
</section>
<section id="analyses-textuelles-exploratoires">
<h2>Analyses textuelles exploratoires<a class="headerlink" href="#analyses-textuelles-exploratoires" title="Link to this heading">Â¶</a></h2>
<p>Pour confirmer le thÃ¨me de notre corpus nous avons scrapÃ© deux autres corpus ayant comme thÃ¨me <code class="docutils literal notranslate"><span class="pre">sport</span></code> et <code class="docutils literal notranslate"><span class="pre">Ã©conomie</span></code>ã€‚</p>
<p>AprÃ¨s avoir normalisÃ© les textes voici les 10 mots les plus courants du corpus santÃ©.</p>
<figure class="align-center" id="id1">
<img alt="../images/sante.png" src="../images/sante.png"/>
<figcaption>
<p><span class="caption-text">Graphe des 10 mots les plus frÃ©quents du corpus de santÃ©</span><a class="headerlink" href="#id1" title="Link to this image">Â¶</a></p>
</figcaption>
</figure>
<p>Par contraintes dâ€™espace nous nâ€™allons pas afficher le mÃªme type de graphes pour le corpus de forum. Notez simplement
que les 3 mots les plus courants sont Â« mÃ©decin Â», Â« dos Â» et Â« lombago Â», ce qui tend Ã  confirmer la validitÃ© de ce
corpus aussi.</p>
<p>Comme cette mÃ©thode ne permet pas dâ€™avoir une vue plus globale de la spÃ©cificitÃ© du corpus, nous avons construit des
graphes de corrÃ©lation basÃ©s sur lâ€™occurrence de mots dans les textes de chaque thÃ¨me. Le graphe est assez facile Ã 
interprÃ©ter : 1) plus un token sâ€™approche de la ligne, plus la frÃ©quence de ce premier est proche dans deux tableaux 2)
plus il y a de mots Ã  proximitÃ© de la ligne, plus les deux tableaux contiennent les mÃªmes mots Ã  frÃ©quence semblable.</p>
<p>Le nombre considÃ©rable de mots de frÃ©quence similaire entre le corpus santÃ© sÃ©parÃ© en deux montre encore une fois la
validitÃ© de lâ€™hypothÃ¨se selon laquelle les articles de diffÃ©rents thÃ¨mes sont caractÃ©risÃ©s par les mots non-vides les
plus frÃ©quents.</p>
<figure class="align-center" id="id2">
<img alt="../images/correlation.png" src="../images/correlation.png"/>
<figcaption>
<p><span class="caption-text">Graphe de corrÃ©lation pour 3 corpus de diffÃ©rents genres</span><a class="headerlink" href="#id2" title="Link to this image">Â¶</a></p>
</figcaption>
</figure>
</section>
<section id="echantillonnage-des-corpus-et-standardisation-des-etiquettes-d-annotation">
<h2>Ã‰chantillonnage des corpus et standardisation des Ã©tiquettes dâ€™annotation<a class="headerlink" href="#echantillonnage-des-corpus-et-standardisation-des-etiquettes-d-annotation" title="Link to this heading">Â¶</a></h2>
<section id="strategie-dechantillonnage-des-deux-corpus">
<h3>StratÃ©gie dâ€™Ã©chantillonnage des deux corpus<a class="headerlink" href="#strategie-dechantillonnage-des-deux-corpus" title="Link to this heading">Â¶</a></h3>
<p>Vu la quantitÃ© de textes et le manque de personnel il nous a paru impossible dâ€™annoter tous les deux corpus. Il nâ€™est
pas pour autant prÃ©fÃ©rable dâ€™annoter uniquement quelques articles ou quelques posts pour faire lâ€™Ã©valuation car
lâ€™intÃ©rÃªt de lâ€™aspiration se trouvera fortement diminuÃ©.</p>
<p>Nous avons dÃ©cidÃ© dâ€™extraire un Ã©chantillon de chacun des deux corpus avec une mÃ©thode qui permettrait Ã  cet Ã©chantillon
de reprÃ©senter plus ou moins lâ€™ensemble du corpus.</p>
<p>Par souci de concision, nous ne prenons uniquement le corpus de presse comme exemple pour dÃ©montrer la mÃ©thodologie.
Lâ€™Ã©chantillonnage a Ã©tÃ© effectuÃ© avec le mÃªme principe pour le corpus de forum.</p>
<p>Nous avons dâ€™abord calculÃ© la distribution des longueurs de mots de lâ€™ensemble des phrases du corpus de presse. Les 4
quartiles de la distribution sont 16, 25, 36 et 115, Ã  savoir que Â¼ de phrases ont une longueur &lt;= 16 et ainsi de suite.
La figure suivante illustre cette distribution :</p>
<figure class="align-center" id="id3">
<img alt="../images/distribution.png" src="../images/distribution.png"/>
<figcaption>
<p><span class="caption-text">Distribution de longueurs de phrases du corpus de presse</span><a class="headerlink" href="#id3" title="Link to this image">Â¶</a></p>
</figcaption>
</figure>
<p>Pour que ces quatre catÃ©gories de phrases soient Ã©galement reprÃ©sentÃ©es, nous avons gÃ©nÃ©rÃ© 60 nombres alÃ©atoires par
catÃ©gorie pour extraire alÃ©atoirement 60 phrases par catÃ©gorie.</p>
<p>Ã€ la fin de cette phase nous avons pu recenser 6798 mots pour le corpus de presse et 6094 pour le corpus de forum. Ces
deux Ã©chantillons constituent une bonne base pour garantir la comparabilitÃ© concernant lâ€™annotation de ces deux types de
corpus.</p>
</section>
<section id="standardisation-des-etiquettes">
<h3>Standardisation des Ã©tiquettes<a class="headerlink" href="#standardisation-des-etiquettes" title="Link to this heading">Â¶</a></h3>
<p>Si les deux taggers Spacy et StanfordNLP ont recours aux Ã©tiquettes de Universal Dependencies (
UD, <a class="reference external" href="https://universaldependencies.org/u/pos/all.html#al-u-pos/NUM">Nivre et al., 2016</a>), Treetagger utilise des
Ã©tiquettes basÃ©es sur le jeu dâ€™Ã©tiquettes de Penn
Treebank (<a class="reference external" href="https://www.cis.unimuenchen.de/~schmid/tools/TreeTagger/data/french-tagset.html">Marcus et al., 1993</a>). Ces
deux systÃ¨mes ne sont pas entiÃ¨rement convertibles. Par exemple lâ€™Ã©tiquette Â« aux Â» nâ€™existe pas dans Treetagger
franÃ§ais et de lâ€™autre cÃ´tÃ©, lâ€™Ã©tiquette Â« SYM Â» en UD nâ€™a pas dâ€™Ã©quivalent dans Treetagger.</p>
<p>Le cas le plus dÃ©licat est lâ€™Ã©tiquette de Â« SCONJ Â» en UD qui recense des conjonctions de subordination telles que Â« que
Â», Â« si Â» et Â« quand Â», etc. alors que ces mots sont tous Ã©tiquetÃ©s en Â« PRO:REL Â» (pronoms relatifs) dans Treetagger.</p>
<p>Treetagger aussi propose une Ã©tiquette Â« ABR Â» (abrÃ©viation) qui est difficilement dÃ©finissable, nous lâ€™avons assimilÃ© Ã 
la catÃ©gorie Â« PROPN Â» (nom propre) en UD.</p>
<p>Le tableau suivant dÃ©taille notre choix pour convertir au maximum les Ã©tiquettes de Treetagger en UD.</p>
<figure class="align-center">
<img alt="../images/e606f6f0.png" src="../images/e606f6f0.png"/>
</figure>
<figure class="align-center" id="id4">
<img alt="../images/8dba10bb.png" src="../images/8dba10bb.png"/>
<figcaption>
<p><span class="caption-text">Conversion des tags de TreeTagger en tags dâ€™UD</span><a class="headerlink" href="#id4" title="Link to this image">Â¶</a></p>
</figcaption>
</figure>
<p>Une derniÃ¨re question porte sur la lemmatisation. Treetagger parfois attribue une sous-Ã©tiquette @card@ Ã  des chiffres.
Nous avons transformÃ© systÃ©matiquement ce lemme en token original pour garantir la fiabilitÃ© des mesures ultÃ©rieures.</p>
</section>
<section id="quelques-problemes-mineurs">
<h3>Quelques problÃ¨mes mineurs<a class="headerlink" href="#quelques-problemes-mineurs" title="Link to this heading">Â¶</a></h3>
<p>Il nous a paru utile de prÃ©ciser ici quelques problÃ¨mes rencontrÃ©s durant la standardisation dâ€™Ã©tiquettes pour permettre
une meilleure reproductibilitÃ© de codes :</p>
<ol class="simple">
<li><p>Les trois points Â« â€¦ Â» sâ€™Ã©tiquettent tantÃ´t comme trois symboles tantÃ´t comme un seul symbole. Nous avons standardisÃ©
la transcription en trois symboles pour Ã  la fois rendre lâ€™annotation plus comparable et Ã©viter des problÃ¨mes
dâ€™encodage.</p></li>
<li><p>Spacy nâ€™arrive pas Ã  tokÃ©niser â€˜Â«â€™ et â€˜Â»â€™. En plus de ne pas reconnaÃ®tre cette ponctuation, il insÃ¨re
systÃ©matiquement une ligne vide aprÃ¨s ces deux tokens. Cela rend les mesures de prÃ©cision trÃ¨s difficiles et nous
avons dÃ» remplacer tous les guillemets franÃ§ais par les guillemets anglais dans les deux Ã©chantillons de corpus avant
de les faire annoter automatiquement.</p></li>
<li><p>Les espaces insÃ©cables peuvent aussi causer des problÃ¨mes dâ€™annotation. Nous les avons remplacÃ©s tous par des espaces
normaux.</p></li>
</ol>
</section>
</section>
<section id="evaluation-des-taggers">
<h2>Ã‰valuation des taggers<a class="headerlink" href="#evaluation-des-taggers" title="Link to this heading">Â¶</a></h2>
<section id="presentation-generale-des-taggers">
<h3>PrÃ©sentation gÃ©nÃ©rale des taggers<a class="headerlink" href="#presentation-generale-des-taggers" title="Link to this heading">Â¶</a></h3>
<p>Les taggers morphosyntaxiques sont nombreux sur le marchÃ©, ci-dessous une liste de quelques taggers pour le franÃ§ais
utilisÃ©s dans la littÃ©rature :</p>
<figure class="align-center" id="id5">
<img alt="../images/266bcab0.png" src="../images/266bcab0.png"/>
<figcaption>
<p><span class="caption-text">Liste non exhaustive de diffÃ©rents taggers disponibles pour le franÃ§ais (https://github.com/clement-plancq/outils-corpus)</span><a class="headerlink" href="#id5" title="Link to this image">Â¶</a></p>
</figcaption>
</figure>
<p>Le principe des taggers peut Ãªtre fort simple. Un algorithme simpliste qui catÃ©gorise les mots connus dans le tag le
plus courant et les mots inconnus dans les noms propres peut atteindre une prÃ©cision globale de 90% sur des donnÃ©es en
anglais (Charniak, 1997).</p>
<p>Cependant des difficultÃ©s considÃ©rables existent pour atteindre une prÃ©cision plus Ã©levÃ©e. Entre les principales
difficultÃ©s nous pouvons citer le fait curieux que la plupart des types formant le vocabulaire sont non ambigus qui ne
peuvent porter quâ€™une catÃ©gorie morphosyntaxique. Or, ces derniers sont les plus frÃ©quents dans les textes.</p>
<figure class="align-center" id="id6">
<img alt="../images/e90103e4.png" src="../images/e90103e4.png"/>
<figcaption>
<p><span class="caption-text">RÃ©partition des mots ambigus et non-ambigus dans deux corpus dâ€™anglais (Jurafsky, 2000)</span><a class="headerlink" href="#id6" title="Link to this image">Â¶</a></p>
</figcaption>
</figure>
<p>DiffÃ©rents types dâ€™Ã©tiqueteurs existent.</p>
<p>Des Ã©tiqueteurs Ã  bases de rÃ¨gles qui utilisent lexique (forme flÃ©chie, POS, morpho, lemme) et de grammaires locales (
ex : Unitex). Ce type dâ€™Ã©tiqueteurs ont notamment lâ€™avantage dâ€™avoir des rÃ¨gles explicites et modifiables aisÃ©ment et
dâ€™Ãªtre facilement implÃ©mentables (automates finis). Mais lâ€™Ã©criture manuelle des rÃ¨gles est difficile et coÃ»teux et
lâ€™adaptation Ã  de nouvelles donnÃ©es difficile, ce qui fait quâ€™ils ne sont plus trÃ¨s utilisÃ©s aujourdâ€™hui.</p>
<p>Une autre famille dâ€™Ã©tiqueteurs est basÃ©e sur des mÃ©thodes probabilistes, ce qui les rend trÃ¨s performants. Le comble,
câ€™est que ce genre de mÃ©thodes nÃ©cessite moins dâ€™expertise par rapport aux Ã©tiqueteurs Ã  bases de rÃ¨gles. Les chaÃ®nes de
Markov sont au cÅ“ur de la plupart des algorithmes utilisÃ©s et de nombreuses variantes sont possibles (entropie maximale,
SVM, CRF, etc.)</p>
<p>Cependant les taggers basÃ©s sur lâ€™apprentissage statistique nÃ©cessitent un corpus de rÃ©fÃ©rence annotÃ©. Ce type de
protocoles nÃ©cessitent un grand investissement de temps. De plus, il nâ€™est pas toujours aisÃ© dâ€™analyser les erreurs.</p>
</section>
<section id="spacy-treetagger-et-stanfordnlp">
<h3>Spacy, TreeTagger et StanfordNLP<a class="headerlink" href="#spacy-treetagger-et-stanfordnlp" title="Link to this heading">Â¶</a></h3>
<p>Les taggers morphosyntaxiques utilisÃ©s ici sont Spacy, TreeTagger et StanfordNLP (dÃ©sormais appelÃ© Stanza). Il est Ã 
noter que le nom du dernier tagger peut prÃªter Ã  confusion car il existe aussi un framework appelÃ© Stanford CoreNLP (
Manning et al., 2014) qui est surtout connu pour sa performance sur des donnÃ©es en anglais et ses fonctions avancÃ©es
telles que rÃ©solution de corÃ©fÃ©rence. Nous verrons dans la suite de cette section que ce framework nâ€™est pas adaptÃ©
notre projet et que le StanfordNLP utilisÃ© dans ce rapport est bien le StanfordNLP en Python appelÃ© aujourdâ€™hui Stanza.</p>
<p>Tous ces trois taggers sont des taggers basÃ©s sur des mÃ©thodes probabilistes. Le cÅ“ur des algorithmes de ces taggers
repose sur des ngram utilisÃ©s pour modÃ©liser la probabilitÃ© dâ€™une sÃ©quence de mots tagguÃ©s.</p>
<ul class="simple">
<li><p>TreeTagger repose Ã©galement sur des ngram mais il utilise des arbres de dÃ©cision binaires pour estimer les
probabilitÃ©s de transition entre les mots de la sÃ©quence (Schmid, 1994). Câ€™est un modÃ¨le Ã©crit en C et trÃ¨s utilisÃ©
pour le franÃ§ais car il est gratuit (mais propriÃ©taire), rapide et propose de nombreux modÃ¨les. Cependant, on ne sait
presque rien sur les donnÃ©es utilisÃ©es pour entraÃ®ner le modÃ¨le franÃ§ais. Les Ã©tiquettes de TreeTagger sont basÃ©es sur
le tagset de Penn Treebank. Pour le modÃ¨le franÃ§ais, les fonctions tokÃ©nisation, lemmatisation, annotation
morphosyntaxique et chunking sont proposÃ©es.</p></li>
<li><p>Spacy est une librairie relativement jeune (2015). Câ€™est une librairie polyvalente de Python qui dans le cas du
franÃ§ais est Ã©quipÃ©e de tokÃ©niseur, POS tagger, tagger de dÃ©pendance syntaxique, chunkeur, identifieur de NER etcâ€¦
Spacy est entraÃ®nÃ© sur UD French-Sequoia et WikiNER, ce qui fait quâ€™il serait moins performant sur les textes dâ€™autres
genres comme les posts de forum. Il est Ã  noter que deux modÃ¨les existent pour le franÃ§ais, le modÃ¨le utilisÃ© dans
notre projet est le plus grand fr_core_news_md (84 Mb). Lâ€™un de ses grands atouts est sa Â« industry level speed Â». â€¢
Stanford CoreNLP est un framework Ã©crit en Java applicable Ã  6 langues. Câ€™est un framework puissant qui propose des
fonctions poussÃ©es comme lâ€™analyse sentimentale. Cependant le modÃ¨le actuel pour le franÃ§ais nâ€™a pas de lemmatisateur.</p></li>
<li><p>Stanford CoreNLP est un framework Ã©crit en Java applicable Ã  6 langues. Câ€™est un framework puissant qui propose des
fonctions poussÃ©es comme lâ€™analyse sentimentale. Cependant le modÃ¨le actuel pour le franÃ§ais nâ€™a pas de lemmatisateur.</p></li>
</ul>
<figure class="align-center" id="id7">
<img alt="../images/597aa052.png" src="../images/597aa052.png"/>
<figcaption>
<p><span class="caption-text">FonctionnalitÃ©s disponibles de Stanford CoreNLP pour 6 langues</span><a class="headerlink" href="#id7" title="Link to this image">Â¶</a></p>
</figcaption>
</figure>
<p>Enfin StanfordNLP est un framework de Python basÃ© sur PyTorch et applicable Ã  66 langues Ã  lâ€™heure actuelle. Câ€™est un
framework puissant et Ã©galement un grand consommateur de capacitÃ©s de calcul car il est basÃ© sur des rÃ©seaux de
neurones.</p>
<figure class="align-center" id="id8">
<img alt="../images/f9aca8e1.png" src="../images/f9aca8e1.png"/>
<figcaption>
<p><span class="caption-text">CaractÃ©ristiques techniques de StanfordNLP par rapport Ã  dâ€™autres frameworks en TAL (Qi et al., 2020)</span><a class="headerlink" href="#id8" title="Link to this image">Â¶</a></p>
</figcaption>
</figure>
</section>
<section id="evaluation-sur-le-plan-de-la-vitesse-de-traitement">
<h3>Ã‰valuation sur le plan de la vitesse de traitement<a class="headerlink" href="#evaluation-sur-le-plan-de-la-vitesse-de-traitement" title="Link to this heading">Â¶</a></h3>
<p>Pour cette tÃ¢che nous avons construit un gros corpus de 568 000 mots en dupliquant simplement un corpus de base. Les
commandes utilisÃ©es pour Ã©valuer les 4 taggers sont :</p>
<ul class="simple">
<li><p>Stanford CoreNLP</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">command</span><span class="w"> </span><span class="nb">time</span><span class="w"> </span>java-Xmx6g<span class="w"> </span>-cp<span class="w"> </span><span class="s2">"*"</span><span class="w"> </span>edu.stanford.nlp.pipeline.StanfordCoreNLP<span class="w"> </span>-props<span class="w"> </span>french.properties
</pre></div>
</div>
<ul class="simple">
<li><p>TreeTagger</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">command</span><span class="w"> </span><span class="nb">time</span><span class="w"> </span>tree-tagger-french<span class="w"> </span>testAnnotator.txt
</pre></div>
</div>
<ul class="simple">
<li><p>Spacy</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"fr_core_news_md"</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="p">[</span><span class="s2">"ner"</span><span class="p">,</span> <span class="s2">"parser"</span><span class="p">])</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="mi">343000</span>  <span class="c1"># as long as &gt; 1000000 and you don't run out of RAM</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>StanfordNLP (Stanza)</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">stanza</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">lang</span><span class="o">=</span><span class="s1">'fr'</span><span class="p">,</span> <span class="n">processors</span><span class="o">=</span><span class="s1">'tokenize,mwt,pos,lemma,depparse'</span><span class="p">)</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
</pre></div>
</div>
<p>Nous avons montrÃ© le code car la comparaison de vitesse est une tÃ¢che bien dÃ©licate. Sans spÃ©cifier la configuration on
peut parfois Ãªtre littÃ©ralement ahuri par des Ã©valuations fournies sur Internet. StanfordNLP fournit par exemple un
record de 4.51 millions de mots par seconde sur <a class="reference external" href="https://nlp.stanford.edu/software/tokenizer.shtml">leur page</a> alors
quâ€™il sâ€™agit simplement dâ€™une tÃ¢che de tokÃ©nisation effectuÃ©e en plus par un tokÃ©niseur par rÃ¨gles. Spacy paraÃ®trait
bien plus lent par rapport Ã  cet exploit car il nâ€™affiche que 13 963 mots par seconde
sur <a class="reference external" href="https://spacy.io/usage/facts-figures">sa page officielle</a>. Or il nâ€™en est rien car Spacy tient compte aussi du
processus dâ€™annotation de dÃ©pendance syntaxique. Câ€™est pour dire combien il est important de prÃ©ciser les paramÃ¨tres
lorsquâ€™on parle de vitesse de traitement.</p>
<p>Dans notre cas, tous les 4 taggers (sauf Stanford CoreNLP) ont effectuÃ© une tÃ¢che de tokÃ©nisation + lemmatisation +
annotation morphosyntaxique. Le tableau suivant rÃ©sume les rÃ©sultats du test.</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-align:center"><p>Framework</p></th>
<th class="head"><p>Temps de traitement pour 568000 mots</p></th>
<th class="head"><p>Vitesses de traitement (mots par seconde)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>TreeTagger</p></td>
<td><p>71.97 secondes</p></td>
<td><p>8000 m/s</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>StanfordCoreNLP</p></td>
<td><p>609.5 secondes</p></td>
<td><p>568 m/s</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>Spacy</p></td>
<td><p>60 secondes</p></td>
<td><p>9467 m/s</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>StanfordNLP (Stanza)</p></td>
<td><p>20 minutes</p></td>
<td><p>473 m/s</p></td>
</tr>
</tbody>
</table></div>
<p>Vitesse dâ€™annotation de 4 taggers sur un corpus de 568000 mots</p>
<p>Pour mieux apprÃ©cier la validitÃ© de notre test, voici les caractÃ©ristiques techniques de notre ordinateur :</p>
<figure class="align-center" id="id9">
<img alt="../images/d18df612.png" src="../images/d18df612.png"/>
<figcaption>
<p><span class="caption-text">Configuration de lâ€™ordinateur utilisÃ© pour Ã©valuer la vitesse dâ€™annotation de 4 taggers</span><a class="headerlink" href="#id9" title="Link to this image">Â¶</a></p>
</figcaption>
</figure>
<p>Nous voyons bien que Stanford NLP est le plus lent et Spacy le plus rapide. Cependant quelques remarques prÃ©liminaires
mÃ©ritent dâ€™Ãªtre avancÃ©es ici. Tout dâ€™abord Spacy est un modÃ¨le mettant lâ€™accent sur la vitesse, comme fait remarquer
avec pertinence lâ€™auteur de Stanford NLP dans son article (Qi et al., 2020). Nous verrons par la suite quâ€™au niveau de
la prÃ©cision Câ€™est Stanford NLP qui lâ€™emporte. Ensuite Stanford NLP permet une accÃ©lÃ©ration considÃ©rable si une carte
GPU est disponible. Nous nâ€™avons pas pu faire un essai faute dâ€™Ã©quipement. Cependant des entreprises peuvent trÃ¨s bien
avoir les moyens de sâ€™en fournir, ce qui rÃ©duire lâ€™Ã©cart de vitesse entre les deux frameworks.</p>
<p>TreeTagger sâ€™est classÃ© le deuxiÃ¨me. Cependant la vitesse de TreeTagger, comme nous le verrons plus tard, est obtenue au
prix dâ€™une perte considÃ©rable de prÃ©cision.</p>
<p>Enfin un dernier mot sur Stanford CoreNLP. La vitesse de traitement est lente. Elle sera dâ€™autant plus lente si lâ€™on
considÃ¨re que la tÃ¢che de lemmatisation nâ€™a pas Ã©tÃ© effectuÃ©e car indisponible pour le franÃ§ais (voir plus haut). De
plus il faut rappeler quâ€™ici nous avons utilisÃ© le prÃ©fixe java -Xmx6g, Ã  savoir que nous avons allouÃ© 6g de mÃ©moires au
programme pour la tÃ¢che en question. En effet nous avons fait plusieurs tests et il sâ€™est avÃ©rÃ© que 6g de mÃ©moires est
un minimum pour que le programme puisse aboutir. Compte tenu de ces facteurs nous avons dÃ©cidÃ© dâ€™examiner uniquement
StanfordNLP pour la suite de lâ€™Ã©valuation.</p>
</section>
<section id="evaluation-sur-le-plan-de-la-precision">
<h3>Ã‰valuation sur le plan de la prÃ©cision<a class="headerlink" href="#evaluation-sur-le-plan-de-la-precision" title="Link to this heading">Â¶</a></h3>
<p>Dans les sous-sections qui suivent nous prÃ©sentons notamment les mesures de prÃ©cision, de rappel et le F-mesure tout en
sachant que dans des tÃ¢ches dâ€™annotation on met en avant la prÃ©cision.</p>
<p>Les deux Ã©chantillons de corpus ont Ã©tÃ© annotÃ©s manuellement par nos soins, servant de Â« gold standard Â».</p>
<p>Voici les premiÃ¨res lignes de notre gold standard du corpus de forum, notons lâ€™annotation de Â« a Â» en adposition car il
sâ€™agit ici dâ€™une faute dâ€™orthographe typique de ce genre de corpus :</p>
<p>Nous commenÃ§ons par les tests sur le corpus de presse.</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-align:left"><p>Metric</p></th>
<th class="head text-align:right"><p>col1</p></th>
<th class="head text-align:right"><p>col2</p></th>
<th class="head text-align:right"><p>f1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Tokens</p></td>
<td class="text-align:right"><p>99.87</p></td>
<td class="text-align:right"><p>99.82</p></td>
<td class="text-align:right"><p>99.84</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>UPOS</p></td>
<td class="text-align:right"><p>97.15</p></td>
<td class="text-align:right"><p>97.1</p></td>
<td class="text-align:right"><p>97.12</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Lemmas</p></td>
<td class="text-align:right"><p>95.21</p></td>
<td class="text-align:right"><p>95.16</p></td>
<td class="text-align:right"><p>95.18</p></td>
</tr>
</tbody>
</table></div>
<p>Tableau des mesures de prÃ©cision de StanfordNLP sur le corpus de presse</p>
<p>Nous voyons que les rÃ©sultats de StanfordNLP ont Ã©tÃ© plutÃ´t satisfaisant sur le corpus de presse. Cela est plutÃ´t
prÃ©dictible car il sâ€™agit dâ€™un corpus de franÃ§ais Ã©crit relativement formel. Nous menons une discussion en dÃ©tail dans
une sous-section dÃ©diÃ©e spÃ©cialement Ã  lâ€™analyse des erreurs et nous nous contentons de donner des rÃ©sultats en chiffres
dans cette sous-section.</p>
<p>Les rÃ©sultats de Spacy sont moins bons que StanfordNLP mais assez satisfaisants :</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-align:left"><p>Metric</p></th>
<th class="head text-align:right"><p>precision</p></th>
<th class="head text-align:right"><p>recall</p></th>
<th class="head text-align:right"><p>f1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Tokens</p></td>
<td class="text-align:right"><p>97.69</p></td>
<td class="text-align:right"><p>99.12</p></td>
<td class="text-align:right"><p>98.4</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>UPOS</p></td>
<td class="text-align:right"><p>90.53</p></td>
<td class="text-align:right"><p>91.85</p></td>
<td class="text-align:right"><p>91.19</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Lemmas</p></td>
<td class="text-align:right"><p>87.77</p></td>
<td class="text-align:right"><p>89.05</p></td>
<td class="text-align:right"><p>88.41</p></td>
</tr>
</tbody>
</table></div>
<p>Tableau des mesures de prÃ©cision de Spacy sur le corpus de presse</p>
<p>Enfin, les rÃ©sultats de TreeTagger sont les moins bons :</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-align:left"><p>Metric</p></th>
<th class="head text-align:right"><p>precision</p></th>
<th class="head text-align:right"><p>recall</p></th>
<th class="head text-align:right"><p>f1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Tokens</p></td>
<td class="text-align:right"><p>93.71</p></td>
<td class="text-align:right"><p>89</p></td>
<td class="text-align:right"><p>91.29</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>UPOS</p></td>
<td class="text-align:right"><p>83.72</p></td>
<td class="text-align:right"><p>79.52</p></td>
<td class="text-align:right"><p>81.57</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Lemmas</p></td>
<td class="text-align:right"><p>90.25</p></td>
<td class="text-align:right"><p>85.73</p></td>
<td class="text-align:right"><p>87.93</p></td>
</tr>
</tbody>
</table></div>
<p>Tableau des mesures de prÃ©cisions de TreeTagger sur le corpus de presse</p>
<p>Voici les rÃ©sultats des tests sur le corpus de forum.</p>
<p>Nous commenÃ§ons toujours par le tagger de StanfordNLP :</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-align:left"><p>Metric</p></th>
<th class="head text-align:right"><p>precision</p></th>
<th class="head text-align:right"><p>recall</p></th>
<th class="head text-align:right"><p>f1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Tokens</p></td>
<td class="text-align:right"><p>92.5</p></td>
<td class="text-align:right"><p>91.34</p></td>
<td class="text-align:right"><p>91.92</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>UPOS</p></td>
<td class="text-align:right"><p>90.75</p></td>
<td class="text-align:right"><p>91.59</p></td>
<td class="text-align:right"><p>91.17</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Lemmas</p></td>
<td class="text-align:right"><p>93.68</p></td>
<td class="text-align:right"><p>93.52</p></td>
<td class="text-align:right"><p>93.6</p></td>
</tr>
</tbody>
</table></div>
<p>Tableau des mesures de prÃ©cision de StanfordNLP sur le corpus de forum</p>
<p>Le tagger de Spacy :</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-align:left"><p>Metric</p></th>
<th class="head text-align:right"><p>precision</p></th>
<th class="head text-align:right"><p>recall</p></th>
<th class="head text-align:right"><p>f1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Tokens</p></td>
<td class="text-align:right"><p>88.92</p></td>
<td class="text-align:right"><p>86.79</p></td>
<td class="text-align:right"><p>87.84</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>UPOS</p></td>
<td class="text-align:right"><p>87.29</p></td>
<td class="text-align:right"><p>88.17</p></td>
<td class="text-align:right"><p>87.73</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Lemmas</p></td>
<td class="text-align:right"><p>86.56</p></td>
<td class="text-align:right"><p>87.43</p></td>
<td class="text-align:right"><p>86.99</p></td>
</tr>
</tbody>
</table></div>
<p>Tableau des mesures de prÃ©cison de Spacy sur le corpus de forum</p>
<p>Et enfin le tagger de TreeTagger, toujours le moins prÃ©cis sur tous les plans :</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-align:left"><p>Metric</p></th>
<th class="head text-align:right"><p>precision</p></th>
<th class="head text-align:right"><p>recall</p></th>
<th class="head text-align:right"><p>f1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Tokens</p></td>
<td class="text-align:right"><p>85.69</p></td>
<td class="text-align:right"><p>84.79</p></td>
<td class="text-align:right"><p>85.24</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>UPOS</p></td>
<td class="text-align:right"><p>79.66</p></td>
<td class="text-align:right"><p>78.91</p></td>
<td class="text-align:right"><p>79.28</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Lemmas</p></td>
<td class="text-align:right"><p>79.83</p></td>
<td class="text-align:right"><p>79.08</p></td>
<td class="text-align:right"><p>79.45</p></td>
</tr>
</tbody>
</table></div>
<p>Tableau des mesures de prÃ©cision de TreeTagger sur le corpus de forum</p>
</section>
</section>
<section id="discussions-generales">
<h2>Discussions gÃ©nÃ©rales<a class="headerlink" href="#discussions-generales" title="Link to this heading">Â¶</a></h2>
<p>Nous commenÃ§ons par quelques remarques gÃ©nÃ©rales valables pour les deux types de corpus :</p>
<p>Sur les plans de la mesure de prÃ©cision, de la mesure de rappel et de F-mesure :</p>
<ul class="simple">
<li><p>La performance des 3 taggers sur le corpus de presse a Ã©tÃ© systÃ©matiquement meilleur que sur le corpus de forum.
Lâ€™Ã©cart en moyenne est 7.2% pour la mesure de prÃ©cision, 5.6% pour la mesure de rappel et 6.3% pour F1-mesure.</p></li>
<li><p>La performance de StanfordNLP a Ã©tÃ© systÃ©matiquement meilleure que les deux autres taggers sur les deux types de
corpus, que ce soit pour la tokÃ©nisation, la lemmatisation et le POS tagging. Spacy se classe le deuxiÃ¨me et
TreeTagger le dernier. Lâ€™Ã©cart moyen pour les trois tÃ¢ches est 3.4% (versus Spacy) et 3.6% (versus TreeTagger) pour la
mesure de prÃ©cision sur le corpus de presse et 5.4% et 10.3% respectivement sur le corpus de forum.</p></li>
</ul>
<p>Pour approfondir lâ€™analyse, nous donnons ici une typologie des erreurs et le comportement des 3 taggers face Ã 
diffÃ©rentes erreurs :</p>
<ul class="simple">
<li><p>Les 3 taggers ont Ã©tÃ© relativement prÃ©cis sur le corpus de presse. Les principales sources dâ€™erreurs viennent de
lâ€™annotation des noms propres. Lorsque ces derniers ne commencent pas par une lettre capitale, tous les 3 taggers ont
pÃªchÃ©, et ce mÃªme pour des noms propres trÃ¨s courants tels que France.</p></li>
<li><p>Pour le corpus de forum, les principales erreurs proviennent des Â« fautes dâ€™orthographes Â». Cette catÃ©gorie de formes
comprend : o des mots rÃ©ellement mal Ã©pelÃ©s (aprÃ©s, Ã§Ã ), mais des fautes comme Â« je regardes Â», Â« je vais lacher (qui
aurait dÃ» Ãªtre lÃ¢cher) Â» sont bien tolÃ©rÃ©es au niveau du POS Tagging car il sâ€™agit toujours dâ€™un verbe. Mais la
lemmatisation reste incorrecte. TreeTagger est le tagger supportant le moins dâ€™erreurs dâ€™orthographes car elles ont
Ã©tÃ© systÃ©matiquement classÃ©es comme X (unknown), entraÃ®nant une chute de performance.</p></li>
</ul>
<p>StanfordNLP gÃ¨re le mieux au niveau les fautes. Il arrive mÃªme Ã  restaurer la bonne forme pour des erreurs comme Â« ca Â»
pour Â« Ã§a Â». Il arrive aussi Ã  classer Â« trÃ©s Â» comme adverbe en se basant sur la distribution des ngrammes.</p>
<p>Spacy se situe entre les deux. Mais il est dÃ©cidÃ©ment meilleur que TreeTagger.</p>
<ul class="simple">
<li><p>Les points oÃ¹ aucun tagger se dÃ©marque des autres</p></li>
</ul>
<p>Des mots distincts soudÃ©s (ilya ; moi,cela ; Bonjourje ; 20euros). Aucun tagger nâ€™est capable de restituer les formes et
faire une tokÃ©nisation correcte.</p>
<p>Des mots Â« propres Â» au langage du forum et dans une moindre mesure au langage familier (@+, + ou -, mm pour mÃªme,
ptite, merciiiiiiiiiiiiii, rha alala). Aucun tagger nâ€™est capable de faire une annotation correcte.</p>
<p>Des Interjections propres au forum ( ;-) ). Aucun tagger nâ€™est capable de traiter ce genre de tokens.</p>
<ul class="simple">
<li><p>TreeTagger ne gÃ¨re pas les symboles. Â« g Â», Â« â‚¬ Â» sont systÃ©matiquement annotÃ©s comme X. Stanford NLP gÃ¨re le mieux.</p></li>
<li><p>TreeTagger ne gÃ¨re pas non plus les formes raccourcis (kinÃ©). Encore une fois StanfordNLP est le meilleur concernant
lâ€™annotation de ce genre de tokens.</p></li>
</ul>
<p>Enfin il nous a paru bon de prÃ©ciser la belle performance de StanfordNLP et de Spacy sur les noms propres. La plupart
des noms propres ont Ã©tÃ© bien tagguÃ©s quand ils commencent par une lettre en majuscule, que cela soit des noms de
mÃ©dicament (Levothyrox, KÃ©toprofÃ¨ne) ; des noms de virus (VHC, Zika, Ebola) ; ou encore des noms de maladie (SGB, SCT).</p>
<p>StanfordNLP Â« reconnaÃ®t Â» mÃªme des parties de corps (prothÃ¨se discale en L4-L5) ou des types de voitures Â« 4x4 Â».
Cependant la prudence est de mise car il peut simplement sâ€™agit dâ€™une diffÃ©rence de stratÃ©gie concernant les rÃ¨gles de
catÃ©gorisation de POS Tag et non pas dâ€™une diffÃ©rence modÃ¨le dâ€™apprentissage statistique.</p>
<p>Par contre sur ce point la performance de TreeTagger a Ã©tÃ© mÃ©diocre. DÃ¨s quâ€™un nom non courant commence une lettre
majuscule il est classÃ© comme X.</p>
<p>Enfin, nous proposons deux tableaux rÃ©capitulant les caractÃ©ristiques principales de ces 3 taggers.</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-align:center"><p>Tagger</p></th>
<th class="head"><p>Vitesse dâ€™annotation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>TreeTagger</p></td>
<td><p>TrÃ¨s rapide</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>Spacy</p></td>
<td><p>Rapide</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>StanfordNLP</p></td>
<td><p>Moyen</p></td>
</tr>
</tbody>
</table></div>
<p>Tableau rÃ©capitulant la vitesse dâ€™annotation des Taggers</p>
<div class="table-wrapper"><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-align:center"><p>Tagger</p></th>
<th class="head"><p>ProblÃ¨mes</p></th>
<th class="head"><p>Performance</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>TreeTagger</p></td>
<td><p>Fautes dâ€™orthographe<br/><br/>Mots liÃ©s<br/><br/>Noms propres<br/><br/>Langage du forum</p></td>
<td><p>Mauvais<br/><br/>Mauvais<br/><br/>Mauvais<br/><br/>Mauvais</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>Spacy</p></td>
<td><p>Fautes dâ€™orthographe<br/><br/>Mots liÃ©s<br/><br/>Noms propres<br/><br/>Langage du forum</p></td>
<td><p>Moyen<br/><br/>Mauvais<br/><br/>Bon<br/><br/>Mauvais</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>StanfordNLP</p></td>
<td><p>Fautes dâ€™orthographe<br/><br/>Mots liÃ©s<br/><br/>Noms propres<br/><br/>Langage du forum</p></td>
<td><p>Bonne tolÃ©rance<br/><br/>Mauvais<br/><br/>Excellent<br/><br/>Mauvais</p></td>
</tr>
</tbody>
</table></div>
<p>Tableau rÃ©capitulant les diffÃ©rences de performance des Taggers face aux problÃ¨mes du corpus de forum</p>
<p>Pour conclure ce rapport, nous voudrions simuler un scÃ©nario oÃ¹ nous agissons en tant que conseiller informatique en
TAL :</p>
<ol class="simple">
<li><p>Si le texte Ã  annoter est du franÃ§ais formel, utilisez plutÃ´t TreeTagger car il est ultrarapide. Cependant il peut
Ãªtre nÃ©cessaire dâ€™ajouter quelques rÃ¨gles sur la catÃ©gorisation des noms non communs commenÃ§ant par une lettre
majuscule.</p></li>
<li><p>Si le texte Ã  annoter est du franÃ§ais familier, utilisez plutÃ´t Spacy car il est relativement rapide et gÃ¨re
relativement bien un franÃ§ais non standard relativement bien transcrit.</p></li>
<li><p>Si le texte est parsemÃ© abondamment de fautes dâ€™orthographes, optez pour StanfordNLP, câ€™est le framework qui supporte
mieux ce type dâ€™erreurs. Cela est vrai surtout lorsque votre backend est Ã©quipÃ© de bons matÃ©riels (GPU de grandes
capacitÃ©s de calcul)</p></li>
<li><p>Si le texte contient beaucoup dâ€™Ã©lÃ©ments propres Ã  un niveau de langage (comme câ€™est le cas de notre Ã©tude sur le
franÃ§ais du forum). EntraÃ®ner vos propres modÃ¨les car peu de modÃ¨les sur le marchÃ© est prÃªt Ã  utiliser face Ã  ce
genre de tÃ¢ches.</p></li>
</ol>
<p>Quelques manques de ce rapport :</p>
<ol class="simple">
<li><p>Faute de temps nous nâ€™avons pu transcrire quâ€™une partie de notre corpus aspirÃ©. Bien que nous ayons procÃ©dÃ© Ã  un
Ã©chantillonnage basÃ© sur les caractÃ©ristiques distributionnelles des corpus, la taille du corpus de rÃ©fÃ©rence nâ€™est
pas encore satisfaisante.</p></li>
<li><p>Lâ€™analyse des erreurs reste qualitative. Il est de plus prÃ©fÃ©rable de pouvoir classer les erreurs par POS Tag.</p></li>
<li><p>La critique est aisÃ©e, lâ€™art est difficile. Il serait intÃ©ressant dâ€™essayer dâ€™entraÃ®ner de nouveaux modÃ¨les pour
pallier manque dâ€™outils adÃ©quats en vue de la transcription des corpus de forum. Comme nous avons vu dans le rapport,
ce type de corpus recÃ¨le des particularitÃ©s comparables ni au franÃ§ais formel, ni au franÃ§ais oral.</p></li>
</ol>
</section>
<section id="notes-supplementaires">
<h2>Notes supplÃ©mentaires<a class="headerlink" href="#notes-supplementaires" title="Link to this heading">Â¶</a></h2>
<p>Les difficultÃ©s des parseurs actuels proviennent principalement du fait que la plupart des Ã©tiqueteurs ont Ã©tÃ© entraÃ®nÃ©s
sur des donnÃ©es utilisant un franÃ§ais relativement soutenu. A titre dâ€™exemples, French Treebank (AbeillÃ© et al., 2003) a
Ã©tÃ© construit sur un corpus tirÃ© de Â« le monde Â». Sequoia Treebank quant Ã  lui a Ã©tÃ© construit sur un mÃ©lange de textes
journalistiques et de textes de Wikipedia (Candito &amp; Seddah, 2012).</p>
</section>
<section id="references">
<h2>RÃ©fÃ©rences<a class="headerlink" href="#references" title="Link to this heading">Â¶</a></h2>
<p>AbeillÃ©, A., ClÃ©ment, L., &amp; Toussenel, F. (2003). Building a treebank for French. In Treebanks (pp. 165â€“187). Springer.</p>
<p>Benzitoun, C., Fort, K., &amp; Sagot, B. (2012). TCOF-POS: Un corpus libre de franÃ§ais parlÃ© annotÃ© en morphosyntaxe.</p>
<p>Candito, M., &amp; Seddah, D. (2012). Le corpus Sequoia: Annotation syntaxique et exploitation pour lâ€™adaptation dâ€™analyseur
par pont lexical.</p>
<p>Charniak, E. (1997). Statistical techniques for natural language parsing. AI Magazine, 18(4), 33â€“33.</p>
<p>Eshkol-Taravella, I., Baude, O., Maurel, D., Hriba, L., Dugua, C., &amp; Tellier, I. (2011).</p>
<p>Un grand corpus oral Â«disponibleÂ»: Le corpus dâ€™OrlÃ©ans 1 1968-2012.</p>
<p>Explosion, A. I. (2017). SpaCy-Industrial-strength Natural Language Processing in Python. URL: Https://Spacy. Io.</p>
<p>Jurafsky, D. (2000). Speech &amp; language processing. Pearson Education India.</p>
<p>Kahane, S., Deulofeu, H.-J., Gerdes, K., Valli, A., &amp; Nasr, A. (2018). Guide dâ€™annotation syntaxique OrfÃ©o (version
Platinum).</p>
<p>Lebart, L., &amp; Salem, A. (1988). Analyse statistique des donnÃ©es textuelles: Questions ouvertes et lexicomÃ©trie. Dunod
Paris. Manning, C. D., Surdeanu, M., Bauer, J., Finkel, J. R., Bethard, S., &amp; McClosky, D. (2014). The Stanford CoreNLP
natural language processing toolkit. Proceedings of 52nd Annual Meeting of the Association for Computational
Linguistics: System Demonstrations, 55â€“60.</p>
<p>Marcus, M., Santorini, B., &amp; Marcinkiewicz, M. A. (1993). Building a large annotated corpus of English: The Penn
Treebank.</p>
<p>Mitchell, R. (2018). Web scraping with Python: Collecting more data from the modern web. Oâ€™Reilly Media, Inc.</p>
<p>Nivre, J., De Marneffe, M.-C., Ginter, F., Goldberg, Y., Hajic, J., Manning, C. D., McDonald, R., Petrov, S., Pyysalo,
S., &amp; Silveira, N. (2016). Universal dependencies v1: A multilingual treebank collection. Proceedings of the Tenth
International Conference on Language Resources and Evaluation (LRECâ€™16), 1659â€“1666.</p>
<p>Qi, P., Zhang, Y., Zhang, Y., Bolton, J., &amp; Manning, C. D. (2020). Stanza: A Python Natural Language Processing Toolkit
for Many Human Languages. ArXiv Preprint ArXiv:2003.07082.</p>
<p>Schmid, H. (1994). TreeTagger-a language independent part-of-speech tagger.</p>
</section>
</section>

      </article>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="02_classification_prenoms_fr.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Classification de prÃ©noms en genre (masculin/fÃ©minin) ğŸ‡«ğŸ‡·</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="index.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">NLP and Machine Learning-related</div>
                
              </div>
            </a>
        </div>

        <div class="related-information">
              Copyright &#169; 2022, Xiaoou Wang
            |
            Built with <a href="https://www.sphinx-doc.org/">Sphinx</a>
              and
              <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
              <a href="https://github.com/pradyunsg/furo">Furo theme</a>.
            |
            <a class="muted-link" href="../sources/nlp/01_compara_anno_fr.md.txt"
               rel="nofollow">
              Show Source
            </a>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Comparer Spacy, StanfordNLP et TreeTagger sur un corpus oral et un corpus de presse ğŸ‡«ğŸ‡·</a><ul>
<li><a class="reference internal" href="#motivation">Motivation</a></li>
<li><a class="reference internal" href="#etiqueteurs-parseurs-choisis">Ã‰tiqueteurs/parseurs choisis</a></li>
<li><a class="reference internal" href="#constitution-du-corpus">Constitution du corpus</a></li>
<li><a class="reference internal" href="#analyses-textuelles-exploratoires">Analyses textuelles exploratoires</a></li>
<li><a class="reference internal" href="#echantillonnage-des-corpus-et-standardisation-des-etiquettes-d-annotation">Ã‰chantillonnage des corpus et standardisation des Ã©tiquettes dâ€™annotation</a><ul>
<li><a class="reference internal" href="#strategie-dechantillonnage-des-deux-corpus">StratÃ©gie dâ€™Ã©chantillonnage des deux corpus</a></li>
<li><a class="reference internal" href="#standardisation-des-etiquettes">Standardisation des Ã©tiquettes</a></li>
<li><a class="reference internal" href="#quelques-problemes-mineurs">Quelques problÃ¨mes mineurs</a></li>
</ul>
</li>
<li><a class="reference internal" href="#evaluation-des-taggers">Ã‰valuation des taggers</a><ul>
<li><a class="reference internal" href="#presentation-generale-des-taggers">PrÃ©sentation gÃ©nÃ©rale des taggers</a></li>
<li><a class="reference internal" href="#spacy-treetagger-et-stanfordnlp">Spacy, TreeTagger et StanfordNLP</a></li>
<li><a class="reference internal" href="#evaluation-sur-le-plan-de-la-vitesse-de-traitement">Ã‰valuation sur le plan de la vitesse de traitement</a></li>
<li><a class="reference internal" href="#evaluation-sur-le-plan-de-la-precision">Ã‰valuation sur le plan de la prÃ©cision</a></li>
</ul>
</li>
<li><a class="reference internal" href="#discussions-generales">Discussions gÃ©nÃ©rales</a></li>
<li><a class="reference internal" href="#notes-supplementaires">Notes supplÃ©mentaires</a></li>
<li><a class="reference internal" href="#references">RÃ©fÃ©rences</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </main>
</div>
    <script id="documentation_options" data-url_root="../" src="../static/documentation_options.js"></script>
    <script src="../static/documentation_options.js?v=5929fcd5"></script>
    <script src="../static/doctools.js?v=888ff710"></script>
    <script src="../static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../static/clipboard.min.js?v=e637711f"></script>
    <script src="../static/copybutton.js?v=56c01ce6"></script>
    <script src="../static/tabs.js?v=967f3e0a"></script>
    <script>
</script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" />
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-58WGY2PHYB"></script>
<script src='https://kit.fontawesome.com/a076d05399.js' crossorigin='anonymous'></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-58WGY2PHYB');
</script>
<!-- Default Statcounter code for nlpinfrench
http://nlpinfrench.fr -->
<script type="text/javascript">
var sc_project=12500373;
var sc_invisible=1;
var sc_security="def60251";
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics
Made Easy - StatCounter" href="https://statcounter.com/"
target="_blank"><img class="statcounter"
src="https://c.statcounter.com/12500373/0/def60251/1/"
alt="Web Analytics Made Easy -
StatCounter"></a></div></noscript>
<!-- End of Statcounter Code -->
<script src="https://cdn.jsdelivr.net/gh/cferdinandi/gumshoe@4.0/dist/gumshoe.polyfills.min.js"></script>
</script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../static/custom.js?v=6433806a"></script>
    <script src="../static/scripts/main.js?digest=e931d09b2a40c1bb82b542effe772014573baf67"></script></body>
</html>